{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Ensemble HAR - 2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "meShuJDoJpx5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89701afe-3fc0-48fb-8715-3b2190d81214"
      },
      "source": [
        "!nvidia-smi -L"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GPU 0: Tesla T4 (UUID: GPU-d2b67cc2-b110-fa60-bef4-1fe19b842cd6)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DzDdcxIBgyse",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21aa5dae-cb87-4f53-db24-a44cdb62d631"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OqLd8RHBg0Ml",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0238ec61-a593-4cba-958b-e8302deb2c1b"
      },
      "source": [
        "# Import necessary Libraries\n",
        "import numpy as np\n",
        "import os\n",
        "import scipy.stats as st\n",
        "import math\n",
        "from sklearn import preprocessing\n",
        "from sklearn import metrics\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics.classification import accuracy_score, recall_score, f1_score\n",
        "from math import exp\n",
        "from math import log\n",
        "import tensorflow as tf\n",
        "\n",
        "import keras\n",
        "from keras import layers\n",
        "# from keras.utils import to_categorical\n",
        "from keras.models import Model, load_model\n",
        "from keras.initializers import glorot_uniform\n",
        "from keras.layers import Input, Dropout, Add, Dense \n",
        "from keras.layers import MaxPooling1D, Reshape, Activation\n",
        "from keras.layers import BatchNormalization, Flatten, Conv1D"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.metrics.classification module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.metrics. Anything that cannot be imported from sklearn.metrics is now part of the private API.\n",
            "  warnings.warn(message, FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U8iWJmU3g8G5"
      },
      "source": [
        "def DataPreparation(data_input_file):\n",
        "  data = np.load(data_input_file, allow_pickle=True)\n",
        "  # for k in data.files:\n",
        "  #   print(k)\n",
        "  X = data['X']\n",
        "  # print(X.shape)\n",
        "  X = X[:, 0, :, :]\n",
        "  # print(X.shape)\n",
        "  Y = data['y']\n",
        "  # print(Y.shape)\n",
        "  folds = data['folds']\n",
        "  classes_number = Y.shape[1]\n",
        "  Y = np.argmax(Y, axis=1)\n",
        "  return X,Y,folds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RjT6-B74GOzr"
      },
      "source": [
        "def DataPreparation_DNN(data_input_file):\n",
        "  data = np.load(data_input_file, allow_pickle=True)\n",
        "  X = data['X']\n",
        "  X = X[:, 0, :, :]\n",
        "  Y = data['y']\n",
        "  n_class = Y.shape[1]\n",
        "  folds = data['folds']\n",
        " \n",
        "  return X,Y,folds,n_class"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pO7NxA8YhB4B"
      },
      "source": [
        "# State-of-the-art ML models\n",
        "def DTC():\n",
        "  from sklearn.tree import DecisionTreeClassifier\n",
        "  model1 = DecisionTreeClassifier()\n",
        "  return model1\n",
        "\n",
        "def KNC():\n",
        "  from sklearn.neighbors import KNeighborsClassifier\n",
        "  model2 = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p = 3)\n",
        "  return model2\n",
        "\n",
        "def LRC():\n",
        "  from sklearn.linear_model import LogisticRegression\n",
        "  model3 = LogisticRegression(multi_class='ovr')\n",
        "  return model3\n",
        "\n",
        "def RForest():\n",
        "  from sklearn.ensemble import RandomForestClassifier\n",
        "  model4 = RandomForestClassifier(max_depth=2, random_state=0)\n",
        "  return model4\n",
        "\n",
        "def AdaBoost():\n",
        "  from sklearn.ensemble import AdaBoostClassifier\n",
        "  model5 = AdaBoostClassifier(n_estimators=150, random_state=0)\n",
        "  return model5\n",
        "\n",
        "def RBFC():\n",
        "  model6 = SVC(C=1.0, kernel='rbf', degree=3, gamma='scale', coef0=0.0,\n",
        "      shrinking=True, probability=True, tol=0.001, cache_size=200,\n",
        "      class_weight=None, verbose=False, max_iter=- 1, decision_function_shape='ovr',\n",
        "      break_ties=False, random_state=None)\n",
        "  return model6\n",
        "\n",
        "\n",
        "# Deep Learning Models\n",
        "def build_Lyu_DNN(row,col,num_classes):\n",
        "  tf.keras.initializers.GlorotNormal(234)\n",
        "  input_layer = tf.keras.Input(shape=(row,col,1,))\n",
        "  layer = tf.keras.layers.TimeDistributed(tf.keras.layers.Flatten())(input_layer)\n",
        "  layer = tf.keras.layers.LSTM(28,return_sequences=True)(layer)\n",
        "  layer = tf.keras.layers.Dropout(0.1)(layer)\n",
        "  layer = tf.keras.layers.LSTM(28,return_sequences=True)(layer)\n",
        "  layer = tf.keras.layers.Dropout(0.1)(layer)\n",
        "  layerconv1 = tf.keras.layers.Conv1D(filters=30,kernel_size=5,  strides=1) (layer)\n",
        "  layerconv1 = tf.keras.layers.Activation('relu')(layerconv1)\n",
        "  layerconv2 = tf.keras.layers.Conv1D(filters=40,kernel_size= 10,strides=1) (layer)\n",
        "  layerconv2 = tf.keras.layers.Activation('relu')(layerconv2)\n",
        "  layerconv3 = tf.keras.layers.Conv1D(filters=50,kernel_size= 15,strides=1) (layer)\n",
        "  layerconv3 = tf.keras.layers.Activation('relu')(layerconv3)\n",
        "  layerconv4 = tf.keras.layers.Conv1D(filters=60,kernel_size= 20,strides=1) (layer)\n",
        "  layerconv4 = tf.keras.layers.Activation('relu')(layerconv4)\n",
        "  max1= tf.reduce_max(layerconv1, 1)\n",
        "  max2= tf.reduce_max(layerconv2, 1)\n",
        "  max3= tf.reduce_max(layerconv3, 1)\n",
        "  max4= tf.reduce_max(layerconv4, 1)\n",
        "  concat_layer = tf.keras.layers.concatenate([max1,max2,max3,max4],1)\n",
        "  layer= tf.keras.layers.Dense(num_classes, activation = 'softmax')   (concat_layer) \n",
        "\n",
        "  model = tf.keras.Model(inputs=input_layer, outputs=layer)\n",
        "  return model\n",
        "\n",
        "\n",
        "\n",
        "def build_model_JGH(row,col,num_classes): \n",
        "  layers = [\n",
        "      tf.keras.layers.TimeDistributed(tf.keras.layers.Flatten()),\n",
        "      tf.keras.layers.LSTM(28,return_sequences=True,  input_shape=(row, col)),  \n",
        "      tf.keras.layers.LSTM(28,return_sequences=True),                           \n",
        "      tf.keras.layers.LSTM(28,return_sequences=True),                           \n",
        "      tf.keras.layers.Dropout(0.1),\n",
        "      tf.keras.layers.Conv1D(filters=64,kernel_size=5,strides=2,activation='relu'),\n",
        "      tf.keras.layers.MaxPool1D(pool_size=2,strides = 2),\n",
        "      tf.keras.layers.Conv1D(filters=128,kernel_size=3,strides=2,activation='relu'),\n",
        "      tf.keras.layers.GlobalAveragePooling1D(),        \n",
        "      tf.keras.layers.BatchNormalization(),     \n",
        "      tf.keras.layers.Dense(num_classes, activation = 'softmax')\n",
        "       ]\n",
        "      \n",
        "  model = tf.keras.Sequential(layers)\n",
        "  return model\n",
        "\n",
        "\n",
        "def identity_block(input, kernel_size, filters, stage, block):\n",
        "  # Variables\n",
        "  filters1, filters2, filters3 = filters\n",
        "  conv_name_base = 'res' + str(stage) + block + '_branch'\n",
        "  bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
        "  # Create layers\n",
        "  output = keras.layers.Conv1D(filters1, 1, kernel_initializer='he_normal', name=conv_name_base + '2a')(input)\n",
        "  output = keras.layers.BatchNormalization(name=bn_name_base + '2a')(output)\n",
        "  output = keras.layers.Activation('relu')(output)\n",
        "  output = keras.layers.Conv1D(filters2, kernel_size, padding='same', kernel_initializer='he_normal', name=conv_name_base + '2b')(output)\n",
        "  output = keras.layers.BatchNormalization(name=bn_name_base + '2b')(output)\n",
        "  output = keras.layers.Activation('relu')(output)\n",
        "  output = keras.layers.Conv1D(filters3, 1, kernel_initializer='he_normal', name=conv_name_base + '2c')(output)\n",
        "  output = keras.layers.BatchNormalization(name=bn_name_base + '2c')(output)\n",
        "  output = keras.layers.add([output, input])\n",
        "  output = keras.layers.Activation('relu')(output)\n",
        "  # Return a block\n",
        "  return output\n",
        "\n",
        "\n",
        "def conv_block(input, kernel_size, filters, stage, block, strides=2):\n",
        "  # Variables\n",
        "  filters1, filters2, filters3 = filters\n",
        "  conv_name_base = 'res' + str(stage) + block + '_branch'\n",
        "  bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
        "  # Create block layers\n",
        "  output = keras.layers.Conv1D(filters1, 1, strides=strides, kernel_initializer='he_normal', name=conv_name_base + '2a')(input)\n",
        "  output = keras.layers.BatchNormalization(name=bn_name_base + '2a')(output)\n",
        "  output = keras.layers.Activation('relu')(output)\n",
        "  output = keras.layers.Conv1D(filters2, kernel_size, padding='same', kernel_initializer='he_normal', name=conv_name_base + '2b')(output)\n",
        "  output = keras.layers.BatchNormalization(name=bn_name_base + '2b')(output)\n",
        "  output = keras.layers.Activation('relu')(output)\n",
        "  output = keras.layers.Conv1D(filters3, 1, kernel_initializer='he_normal', name=conv_name_base + '2c')(output)\n",
        "  output = keras.layers.BatchNormalization(name=bn_name_base + '2c')(output)\n",
        "  shortcut = keras.layers.Conv1D(filters3, 1, strides=strides, kernel_initializer='he_normal', name=conv_name_base + '1')(input)\n",
        "  shortcut = keras.layers.BatchNormalization(name=bn_name_base + '1')(shortcut)\n",
        "  output = keras.layers.add([output, shortcut])\n",
        "  output = keras.layers.Activation('relu')(output)\n",
        "  # Return a block\n",
        "  return output\n",
        "  \n",
        "def build_model_ResNet(row, col, num_classes):\n",
        "  input_shape = (row,col)\n",
        "  # Create an input layer \n",
        "  input = keras.layers.Input(shape=input_shape)\n",
        "  # Create output layers\n",
        "  output = keras.layers.ZeroPadding1D(padding=2, name='padding_conv1')(input)                   #############\n",
        "  output = keras.layers.Conv1D(64, 7, strides=2, use_bias=False, name='conv1')(output)          #############\n",
        "  output = keras.layers.BatchNormalization(name='bn_conv1')(output)\n",
        "  output = keras.layers.Activation('relu', name='conv1_relu')(output)\n",
        "  output = keras.layers.MaxPooling1D(3, strides=2, padding='same', name='pool1')(output)\n",
        "  output = conv_block(output, 3, [64, 64, 256], stage=2, block='a', strides=1)\n",
        "  output = identity_block(output, 3, [64, 64, 256], stage=2, block='b')\n",
        "  output = identity_block(output, 3, [64, 64, 256], stage=2, block='c')\n",
        "  output = conv_block(output, 3, [128, 128, 512], stage=3, block='a')\n",
        "  output = identity_block(output, 3, [128, 128, 512], stage=3, block='b')\n",
        "  output = identity_block(output, 3, [128, 128, 512], stage=3, block='c')\n",
        "  output = identity_block(output, 3, [128, 128, 512], stage=3, block='d')\n",
        "  output = conv_block(output, 3, [256, 256, 1024], stage=4, block='a')\n",
        "  output = identity_block(output, 3, [256, 256, 1024], stage=4, block='b')\n",
        "  output = identity_block(output, 3, [256, 256, 1024], stage=4, block='c')\n",
        "  output = identity_block(output, 3, [256, 256, 1024], stage=4, block='d')\n",
        "  output = identity_block(output, 3, [256, 256, 1024], stage=4, block='e')\n",
        "  output = identity_block(output, 3, [256, 256, 1024], stage=4, block='f')\n",
        "  output = conv_block(output, 3, [512, 512, 2048], stage=5, block='a')\n",
        "  output = identity_block(output, 3, [512, 512, 2048], stage=5, block='b')\n",
        "  output = identity_block(output, 3, [512, 512, 2048], stage=5, block='c')\n",
        "  output = keras.layers.GlobalAveragePooling1D(name='pool5')(output)\n",
        "  output = keras.layers.Dense(num_classes, activation='softmax', name='fc1000')(output)\n",
        "  # Create a model from input layer and output layers\n",
        "  model = keras.models.Model(inputs=input, outputs=output)\n",
        "  # # Print model\n",
        "  # print()\n",
        "  # print(model.summary(), '\\n')\n",
        "  # Compile the model\n",
        "  # Return a model\n",
        "  return model "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6syyoxgnWz7-"
      },
      "source": [
        "# 15 features that we are extracting\n",
        "def A(sample):\n",
        "  feat = []\n",
        "  for col in range(0,sample.shape[1]):\n",
        "      average = np.average(sample[:,col])\n",
        "      feat.append(average)\n",
        "\n",
        "  return feat\n",
        "\n",
        "def SD(sample):\n",
        "  feat = []\n",
        "  for col in range(0, sample.shape[1]):\n",
        "      std = np.std(sample[:, col])\n",
        "      feat.append(std)\n",
        "\n",
        "  return feat\n",
        "\n",
        "def AAD(sample):\n",
        "  feat = []\n",
        "  for col in range(0, sample.shape[1]):\n",
        "      data = sample[:, col]\n",
        "      add = np.mean(np.absolute(data - np.mean(data)))\n",
        "      feat.append(add)\n",
        "\n",
        "  return feat\n",
        "\n",
        "def ARA(sample):\n",
        "  #Average Resultant Acceleration[1]:\n",
        "  # Average of the square roots of the sum of the values of each axis squared √(xi^2 + yi^2+ zi^2) over the ED\n",
        "  feat = []\n",
        "  sum_square = 0\n",
        "  sample = np.power(sample, 2)\n",
        "  for col in range(0, sample.shape[1]):\n",
        "      sum_square = sum_square + sample[:, col]\n",
        "\n",
        "  sample = np.sqrt(sum_square)\n",
        "  average = np.average(sample)\n",
        "  feat.append(average)\n",
        "  return feat\n",
        "\n",
        "def TBP(sample):\n",
        "  from scipy import signal\n",
        "  feat = []\n",
        "  sum_of_time = 0\n",
        "  for col in range(0, sample.shape[1]):\n",
        "      data = sample[:, col]\n",
        "      peaks = signal.find_peaks_cwt(data, np.arange(1,4))\n",
        "      feat.append(peaks.tolist())\n",
        "  return feat\n",
        "\n",
        "def mean_ts(sample, Te=1.0):\n",
        "  feat = []\n",
        "  for col in range(0,sample.shape[1]):\n",
        "    average = np.mean(sample[:,col])\n",
        "    feat.append(average)\n",
        "\n",
        "  return feat\n",
        "\n",
        "def max_ts(sample, Te=1.0):\n",
        "  feat = []\n",
        "  for col in range(0,sample.shape[1]):\n",
        "      average = np.amax(sample[:,col])\n",
        "      feat.append(average)\n",
        "\n",
        "  return feat\n",
        "\n",
        "def min_ts(sample, Te=1.0): \n",
        "  feat = []\n",
        "  for col in range(0,sample.shape[1]):\n",
        "      average = np.amin(sample[:,col]) # min\n",
        "      feat.append(average)\n",
        "\n",
        "  return feat \n",
        "\n",
        "def skew_ts(sample, Te=1.0):    \n",
        "  feat = []\n",
        "  for col in range(0,sample.shape[1]):\n",
        "      average = st.skew(sample[:,col]) # skew\n",
        "      feat.append(average)\n",
        "\n",
        "  return feat\n",
        "\n",
        "def kurtosis_ts(sample, Te=1.0):  \n",
        "  feat = []\n",
        "  for col in range(0,sample.shape[1]):\n",
        "      average = st.kurtosis(sample[:,col]) # kurtosis \n",
        "      feat.append(average)\n",
        "\n",
        "  return feat\n",
        " \n",
        "def iqr_ts(sample, Te=1.0):  \n",
        "  feat = []\n",
        "  for col in range(0,sample.shape[1]):\n",
        "      average = st.iqr(sample[:,col]) # interquartile rate\n",
        "      feat.append(average)\n",
        "\n",
        "  return feat\n",
        "\n",
        "def mad_ts(sample, Te=1.0):  \n",
        "  feat = []\n",
        "  for col in range(0,sample.shape[1]):\n",
        "      average = np.median(np.sort(abs(sample[:,col] - np.median(sample[:,col]))))\n",
        "      feat.append(average)\n",
        "\n",
        "  return feat\n",
        "\n",
        "def area_ts(sample, Te=1.0):  \n",
        "  feat = []\n",
        "  for col in range(0,sample.shape[1]):\n",
        "      average = np.trapz(sample[:,col], dx=Te)\n",
        "      feat.append(average)\n",
        "\n",
        "  return feat                            \n",
        " \n",
        "\n",
        "def sq_area_ts(sample, Te=1.0):\n",
        "  feat = []\n",
        "  for col in range(0,sample.shape[1]):\n",
        "      average = np.trapz(sample[:,col] ** 2, dx=Te)\n",
        "      feat.append(average)\n",
        "\n",
        "  return feat\n",
        "def energy_measure(sample):\n",
        "  \"\"\"Calculates energy measures\"\"\"\n",
        "  feat = []\n",
        "  for col in range(0,sample.shape[1]):\n",
        "\n",
        "    em_x = np.mean(np.square(sample[:,col] ))\n",
        "    feat.append(em_x)\n",
        "  return feat\n",
        "\n",
        "def stat_area_features(x, Te=1.0):\n",
        "  mean_ts = np.mean(x, axis=1).reshape(-1,1) # mean\n",
        "  max_ts = np.amax(x, axis=1).reshape(-1,1) # max\n",
        "  min_ts = np.amin(x, axis=1).reshape(-1,1) # min\n",
        "  std_ts = np.std(x, axis=1).reshape(-1,1) # std\n",
        "  skew_ts = st.skew(x, axis=1).reshape(-1,1) # skew\n",
        "  kurtosis_ts = st.kurtosis(x, axis=1).reshape(-1,1) # kurtosis \n",
        "  iqr_ts = st.iqr(x, axis=1).reshape(-1,1) # interquartile rante\n",
        "  mad_ts = np.median(np.sort(abs(x - np.median(x, axis=1).reshape(-1,1)),\n",
        "                              axis=1), axis=1).reshape(-1,1) # median absolute deviation\n",
        "  area_ts = np.trapz(x, axis=1, dx=Te).reshape(-1,1) # area under curve\n",
        "  sq_area_ts = np.trapz(x ** 2, axis=1, dx=Te).reshape(-1,1) # area under curve ** 2\n",
        "\n",
        "  return np.concatenate((mean_ts,max_ts,min_ts,std_ts,skew_ts,kurtosis_ts,\n",
        "                          iqr_ts,mad_ts,area_ts,sq_area_ts), axis=1)\n",
        "  \n",
        "\n",
        "def frequency_domain_features(x, Te=1.0):\n",
        "  feat=[]\n",
        "  # As the DFT coefficients and their corresponding frequencies are symetrical arrays\n",
        "  # with respect to the middle of the array we need to know if the number of readings \n",
        "  # in x is even or odd to then split the arrays...\n",
        "  if x.shape[1]%2 == 0:\n",
        "      N = int(x.shape[1]/2)\n",
        "  else:\n",
        "      N = int(x.shape[1]/2) - 1\n",
        "  xf = np.repeat(fftfreq(x.shape[1],d=Te)[:N].reshape(1,-1), x.shape[0], axis=0) # frequencies\n",
        "  dft = np.abs(fft(x, axis=1))[:,:N] # DFT coefficients   \n",
        "  \n",
        "  # statistical and area features\n",
        "  # dft_features = stat_area_features(dft, Te=1.0)\n",
        "  # weighted mean frequency\n",
        "  dft_weighted_mean_f = np.average(xf, axis=1, weights=dft).reshape(-1,1)\n",
        "  # 5 first DFT coefficients \n",
        "  dft_first_coef = dft[:,:5]    \n",
        "  # 5 first local maxima of DFT coefficients and their corresponding frequencies\n",
        "  dft_max_coef = np.zeros((x.shape[0],5))\n",
        "  dft_max_coef_f = np.zeros((x.shape[0],5))\n",
        "  for row in range(x.shape[0]):\n",
        "      # finds all local maximas indexes\n",
        "      extrema_ind = argrelextrema(dft[row,:], np.greater, axis=0) \n",
        "      # makes a list of tuples (DFT_i, f_i) of all the local maxima\n",
        "      # and keeps the 5 biggest...\n",
        "      extrema_row = sorted([(dft[row,:][j],xf[row,j]) for j in extrema_ind[0]],\n",
        "                            key=operator.itemgetter(0), reverse=True)[:5] \n",
        "      for i, ext in enumerate(extrema_row):\n",
        "          dft_max_coef[row,i] = ext[0]\n",
        "          dft_max_coef_f[row,i] = ext[1]  \n",
        "\n",
        "  feat.append(np.concatenate((dft_weighted_mean_f,dft_first_coef, dft_max_coef,dft_max_coef_f), axis=1).tolist() )\n",
        "  # print(len(feat))\n",
        "  # print(feat)\n",
        "  return feat\n",
        "\n",
        "## Feature Extraction\n",
        "\n",
        "def feature_extraction(X):\n",
        "  # Extracts the features, as mentioned by Catal et al. 2015\n",
        "  # Average - A,\n",
        "  # Standard Deviation - SD,\n",
        "  # Average Absolute Difference - AAD,\n",
        "  # Average Resultant Acceleration - ARA(1),\n",
        "  # Time Between Peaks - TBP\n",
        "  X_tmp = []\n",
        "  \n",
        "  for sample in X:\n",
        "      features = A(sample)\n",
        "      features = np.hstack((features, A(sample)))\n",
        "      features = np.hstack((features, SD(sample)))\n",
        "      features = np.hstack((features, AAD(sample)))\n",
        "      features = np.hstack((features, ARA(sample)))\n",
        "      \"\"\"\n",
        "      features = np.hstack((features, mean_ts(sample)))\n",
        "      features = np.hstack((features, max_ts(sample)))\n",
        "      features = np.hstack((features, min_ts(sample)))\n",
        "      features = np.hstack((features, kurtosis_ts(sample)))\n",
        "      features = np.hstack((features, iqr_ts(sample)))\n",
        "      features = np.hstack((features, skew_ts(sample)))\n",
        "      features = np.hstack((features, area_ts(sample)))\n",
        "      features = np.hstack((features, sq_area_ts(sample)))\n",
        "      features = np.hstack((features, mad_ts(sample)))\n",
        "      features = np.hstack((features, mean_ts(sample[:,1:]-sample[:,:-1],1)))\n",
        "      features = np.hstack((features, max_ts(sample[:,1:]-sample[:,:-1],1)))\n",
        "      features = np.hstack((features, min_ts(sample[:,1:]-sample[:,:-1],1)))\n",
        "      features = np.hstack((features, kurtosis_ts(sample[:,1:]-sample[:,:-1],1)))\n",
        "      features = np.hstack((features, iqr_ts(sample[:,1:]-sample[:,:-1],1)))\n",
        "      features = np.hstack((features, skew_ts(sample[:,1:]-sample[:,:-1],1)))\n",
        "      features = np.hstack((features, area_ts(sample[:,1:]-sample[:,:-1],1)))\n",
        "      features = np.hstack((features, sq_area_ts(sample[:,1:]-sample[:,:-1],1)))\n",
        "      features = np.hstack((features, mad_ts(sample[:,1:]-sample[:,:-1],1)))\n",
        "      \"\"\"\n",
        "      X_tmp.append(features)\n",
        "      \n",
        "  X = np.array(X_tmp)\n",
        "  \n",
        "  return X\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZukDAfL3HN9C"
      },
      "source": [
        "batch_size = 128\n",
        "epochs = 100\n",
        "learning_rate = 0.001"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t98jR5cYPhWP"
      },
      "source": [
        "# #For JSun\n",
        "# def hidden_layer_generate(cnn_model,X):\n",
        "\n",
        "#     \"\"\"\n",
        "#     CNNの中間層の出力を取得するモデルの構築\n",
        "#     :param cnn_model: CNNモデル\n",
        "#     :return:\n",
        "#     \"\"\"\n",
        "\n",
        "#     layer_name = 'flatten_1'\n",
        "#     hidden_layer_model = tf.keras.models.Model(inputs=cnn_model.input, outputs=cnn_model.layers[6].output)\n",
        "\n",
        "#     cnn_train_result = hidden_layer_model.predict(X)\n",
        "\n",
        "#     return hidden_layer_model, cnn_train_result\n",
        "# def elm_model_generate(hidden_layer_cnn_lstm, y,x,num_classes):\n",
        "\n",
        "#     \"\"\"\n",
        "#     ELMモデルの構築\n",
        "#     \"\"\"\n",
        "\n",
        "#     target_train_oh = tf.keras.utils.to_categorical(y, num_classes)\n",
        "#     print(target_train_oh.shape)\n",
        "\n",
        "#     elm_model = hpelm.elm.ELM(hidden_layer_cnn_lstm.shape[1], num_classes)\n",
        "#     print(hidden_layer_cnn_lstm.shape)\n",
        "#     elm_model.add_neurons(128, func='sigm')\n",
        "\n",
        "#     elm_model.train(hidden_layer_cnn_lstm, y, 'c')\n",
        "\n",
        "#     return elm_model\n",
        "\n",
        "# def predict_ELM(cnn_part, elm_part, X):\n",
        "\n",
        "  \n",
        "\n",
        "#   cnn_result = cnn_part.predict(X)\n",
        "#   elm_result = elm_part.predict(cnn_result)\n",
        "#   return elm_result    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4x12q_wOJ-nH"
      },
      "source": [
        "def Train(X_Train, Y_Train, X_Test, Y_Test, clf):\n",
        "  confidence_factor_list = []\n",
        "  clf.fit(X_Train, Y_Train)\n",
        "  f1 = clf.predict_proba(X_Test)\n",
        "  for i in range(0, f1.shape[0]):\n",
        "    total_fuzzy_sum = sum(f1[i])\n",
        "    confidence_factor_activity = f1[i]/total_fuzzy_sum\n",
        "    confidence_factor_list.append(confidence_factor_activity)\n",
        "  confidence_factor_array = np.asarray(confidence_factor_list)\n",
        "  return confidence_factor_array, Y_Test\n",
        "\n",
        "\n",
        "def Train_Lyu(X, y, X_train, X_test, y_train, y_test, n_class):\n",
        "  _, img_rows, img_cols = X.shape\n",
        "  X=X.reshape(X.shape[0],img_rows,img_cols,1)\n",
        "  _,img_rows, img_cols,_ = X.shape\n",
        "  model=build_Lyu_DNN(img_rows, img_cols, n_class)\n",
        "  optimizer = tf.keras.optimizers.Adam(lr=learning_rate)\n",
        "  model.compile(loss=\"categorical_crossentropy\", optimizer=optimizer,  metrics=['accuracy'])\n",
        "  model.fit(X_train, y_train, batch_size=batch_size,epochs=200,verbose=2)\n",
        "  y_pred = model.predict(X_test)\n",
        "  confidence_factor_list = []\n",
        "  for i in range(0, y_pred.shape[0]):\n",
        "    total_fuzzy_sum = sum(y_pred[i])\n",
        "    confidence_factor_activity = y_pred[i]/total_fuzzy_sum\n",
        "    confidence_factor_list.append(confidence_factor_activity)\n",
        "  confidence_factor_array = np.asarray(confidence_factor_list)\n",
        "  return confidence_factor_array\n",
        "\n",
        "  \n",
        "def Train_JGH(X, y, X_train, X_test, y_train, y_test, n_class): \n",
        "  _,img_rows, img_cols = X.shape\n",
        "  X=X.reshape(X.shape[0],img_rows,img_cols,1)\n",
        "  _,img_rows, img_cols,_ = X.shape\n",
        "  model=build_model_JGH(img_rows,img_cols,n_class)\n",
        "  model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='ADAM')\n",
        "  model.fit(X_train, y_train, batch_size=192, epochs=250,verbose=2)\n",
        "  y_pred = model.predict(X_test)\n",
        "  confidence_factor_list = []\n",
        "  for i in range(0, y_pred.shape[0]):\n",
        "    total_fuzzy_sum = sum(y_pred[i])\n",
        "    confidence_factor_activity = y_pred[i]/total_fuzzy_sum\n",
        "    confidence_factor_list.append(confidence_factor_activity)\n",
        "  confidence_factor_array = np.asarray(confidence_factor_list)\n",
        "  return confidence_factor_array\n",
        "\n",
        "\n",
        "def Train_ResNet(X, y, X_train, X_test, y_train, y_test, n_class): \n",
        "  _,img_rows, img_cols = X.shape\n",
        "  X=X.reshape(X.shape[0],img_rows,img_cols,1)\n",
        "  _,img_rows, img_cols,_ = X.shape\n",
        "  model=build_model_ResNet(img_rows,img_cols,n_class)\n",
        "  model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='ADAM')\n",
        "  model.fit(X_train, y_train, batch_size=192, epochs=150,verbose=2)\n",
        "  y_pred = model.predict(X_test)\n",
        "  confidence_factor_list = []\n",
        "  for i in range(0, y_pred.shape[0]):\n",
        "    total_fuzzy_sum = sum(y_pred[i])\n",
        "    confidence_factor_activity = y_pred[i]/total_fuzzy_sum\n",
        "    confidence_factor_list.append(confidence_factor_activity)\n",
        "  confidence_factor_array = np.asarray(confidence_factor_list)\n",
        "  return confidence_factor_array"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "azD_a8L7disX"
      },
      "source": [
        "def Train_Lyu_Opp(X, Y, X_train, X_test, y_train, y_test, n_class):\n",
        "  n_class = Y.shape[1]\n",
        "  _, img_rows, img_cols = X_train.shape\n",
        "  X=X.reshape(X.shape[0],img_rows,img_cols,1)\n",
        "  _,img_rows, img_cols,_ = X.shape\n",
        "    \n",
        "  model=build_Lyu_DNN(img_rows, img_cols, n_class)\n",
        "  optimizer = tf.keras.optimizers.Adam(lr=learning_rate)\n",
        "  model.compile(loss=\"categorical_crossentropy\", optimizer=optimizer,  metrics=['accuracy'])\n",
        "  model.fit(X_train, y_train, batch_size=batch_size,epochs=200,verbose=2)\n",
        "  y_pred = model.predict(X_test)\n",
        "\n",
        "  confidence_factor_list = []\n",
        "  for i in range(0, y_pred.shape[0]):\n",
        "    total_fuzzy_sum = sum(y_pred[i])\n",
        "    confidence_factor_activity = y_pred[i]/total_fuzzy_sum\n",
        "    confidence_factor_list.append(confidence_factor_activity)\n",
        "  confidence_factor_array = np.asarray(confidence_factor_list)\n",
        "  return confidence_factor_array\n",
        "\n",
        "\n",
        "def Train_JGH_Opp(X, Y, X_train, X_test, y_train, y_test, n_class):\n",
        "  n_class = Y.shape[1]\n",
        "  _, img_rows, img_cols = X.shape\n",
        "  X=X.reshape(X.shape[0],img_rows,img_cols,1)\n",
        "  _,img_rows, img_cols,_ = X.shape\n",
        "\n",
        "  model=build_model_JGH(img_rows,img_cols,n_class)\n",
        "  model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='ADAM')\n",
        "  model.fit(X_train, y_train, batch_size=192, epochs=250,verbose=2)\n",
        "  y_pred = model.predict(X_test)\n",
        "  \n",
        "  confidence_factor_list = []\n",
        "  for i in range(0, y_pred.shape[0]):\n",
        "    total_fuzzy_sum = sum(y_pred[i])\n",
        "    confidence_factor_activity = y_pred[i]/total_fuzzy_sum\n",
        "    confidence_factor_list.append(confidence_factor_activity)\n",
        "  confidence_factor_array = np.asarray(confidence_factor_list)\n",
        "  return confidence_factor_array\n",
        "\n",
        "\n",
        "\n",
        "def Train_ResNet_Opp(X, Y, X_train, X_test, y_train, y_test, n_class):\n",
        "  # n_class = Y.shape[1]\n",
        "  _, img_rows, img_cols = X.shape\n",
        "  X=X.reshape(X.shape[0],img_rows,img_cols,1)\n",
        "  _,img_rows, img_cols,_ = X.shape\n",
        "  model=build_model_ResNet(img_rows,img_cols,n_class)\n",
        "  model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='ADAM')\n",
        "  model.fit(X_train, y_train, batch_size=192, epochs=150,verbose=2)\n",
        "  y_pred = model.predict(X_test)\n",
        "  confidence_factor_list = []\n",
        "  for i in range(0, y_pred.shape[0]):\n",
        "    total_fuzzy_sum = sum(y_pred[i])\n",
        "    confidence_factor_activity = y_pred[i]/total_fuzzy_sum\n",
        "    confidence_factor_list.append(confidence_factor_activity)\n",
        "  confidence_factor_array = np.asarray(confidence_factor_list)\n",
        "  return confidence_factor_array"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "el0xwS6_xA6L"
      },
      "source": [
        "def PredictClass_5(merged_fuzzy_rank_array_1, merged_fuzzy_rank_array_2, merged_fuzzy_rank_array_3, merged_fuzzy_rank_array_4, merged_fuzzy_rank_array_5,\n",
        "                confidence_factor_array_1, confidence_factor_array_2, confidence_factor_array_3, confidence_factor_array_4, confidence_factor_array_5):  \n",
        "\n",
        "  Y_Pred = []\n",
        "  RSc = {}\n",
        "  CFSc = {}\n",
        "  FSc = {}\n",
        "  k = 3#int((fuzzy_rank_array_1.shape[1])/2);\n",
        "  PcR = 0.888\n",
        "  PcCF = 0\n",
        "    \n",
        "  for i in range(0, len(fuzzy_rank_array_1)):\n",
        "    item_1 = merged_fuzzy_rank_array_1[i]\n",
        "    item_2 = merged_fuzzy_rank_array_2[i]\n",
        "    item_3 = merged_fuzzy_rank_array_3[i]\n",
        "    item_4 = merged_fuzzy_rank_array_4[i]\n",
        "    item_5 = merged_fuzzy_rank_array_5[i]\n",
        "    indices_1 = sorted(range(len(item_1)), key=lambda x: item_1[x])[0:k]\n",
        "    indices_2 = sorted(range(len(item_2)), key=lambda x: item_2[x])[0:k]\n",
        "    indices_3 = sorted(range(len(item_3)), key=lambda x: item_3[x])[0:k]\n",
        "    indices_4 = sorted(range(len(item_4)), key=lambda x: item_4[x])[0:k]\n",
        "    indices_5 = sorted(range(len(item_5)), key=lambda x: item_5[x])[0:k]\n",
        "\n",
        "    for j in range(0, len(item_1)):\n",
        "      if j in indices_1:\n",
        "        RSc[j] = item_1[j]\n",
        "        CFSc[j] = 1-((1/5)*confidence_factor_array_1[i][j])\n",
        "      else:\n",
        "        RSc[j] = PcR\n",
        "        CFSc[j] = 1-((1/5)*PcCF)\n",
        "      \n",
        "      if j in indices_2:\n",
        "        RSc[j] += item_2[j]\n",
        "        CFSc[j] += -((1/5)*confidence_factor_array_2[i][j])\n",
        "      else:\n",
        "        RSc[j] += PcR\n",
        "        CFSc[j] += -((1/3)*PcCF)\n",
        "\n",
        "      if j in indices_3:\n",
        "        RSc[j] += item_3[j]\n",
        "        CFSc[j] += -((1/5)*confidence_factor_array_3[i][j])\n",
        "      else:\n",
        "        RSc[j] += PcR\n",
        "        CFSc[j] += -((1/5)*PcCF)\n",
        "\n",
        "      if j in indices_4:\n",
        "        RSc[j] += item_4[j]\n",
        "        CFSc[j] += -((1/5)*confidence_factor_array_4[i][j])\n",
        "      else:\n",
        "        RSc[j] += PcR\n",
        "        CFSc[j] += -((1/5)*PcCF)\n",
        "\n",
        "      if j in indices_5:\n",
        "        RSc[j] += item_5[j]\n",
        "        CFSc[j] += -((1/5)*confidence_factor_array_5[i][j])\n",
        "      else:\n",
        "        RSc[j] += PcR\n",
        "        CFSc[j] += -((1/5)*PcCF)\n",
        "\n",
        "    CFSc_keys = [*CFSc]\n",
        "    # print(\"Keys:\", CFSc_keys)\n",
        "    # for key in CFSc_keys:\n",
        "    #   CFSc[key] = (1 - CFSc[key])\n",
        "    # print(\"RSc: \", RSc)\n",
        "    # print(\"CFSc: \", CFSc)\n",
        "    valid_keys = list(set([*RSc]) & set([*CFSc]))\n",
        "    for key in valid_keys:\n",
        "      FSc[key]= RSc[key]* CFSc[key]\n",
        "    # print(\"FSc: \", FSc)\n",
        "    predicted_class = min(FSc, key=FSc.get)\n",
        "    Y_Pred.append(predicted_class)\n",
        "  return np.asarray(Y_Pred)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w_30F_3ShisW"
      },
      "source": [
        "def PredictClass_3(merged_fuzzy_rank_array_1, merged_fuzzy_rank_array_2, merged_fuzzy_rank_array_3,\n",
        "                confidence_factor_array_1, confidence_factor_array_2, confidence_factor_array_3):  \n",
        "\n",
        "  Y_Pred = []\n",
        "  RSc = {}\n",
        "  CFSc = {}\n",
        "  FSc = {}\n",
        "  k = 3#int((fuzzy_rank_array_1.shape[1])/2);\n",
        "  PcR = 0.888\n",
        "  PcCF = 0\n",
        "    \n",
        "  for i in range(0, len(fuzzy_rank_array_1)):\n",
        "    item_1 = merged_fuzzy_rank_array_1[i]\n",
        "    item_2 = merged_fuzzy_rank_array_2[i]\n",
        "    item_3 = merged_fuzzy_rank_array_3[i]\n",
        "    indices_1 = sorted(range(len(item_1)), key=lambda x: item_1[x])[0:k]\n",
        "    indices_2 = sorted(range(len(item_2)), key=lambda x: item_2[x])[0:k]\n",
        "    indices_3 = sorted(range(len(item_3)), key=lambda x: item_3[x])[0:k]\n",
        "\n",
        "    for j in range(0, len(item_1)):\n",
        "      if j in indices_1:\n",
        "        RSc[j] = item_1[j]\n",
        "        CFSc[j] = 1-((1/3)*confidence_factor_array_1[i][j])\n",
        "      else:\n",
        "        RSc[j] = PcR\n",
        "        CFSc[j] = 1-((1/3)*PcCF)\n",
        "      \n",
        "      if j in indices_2:\n",
        "        RSc[j] += item_2[j]\n",
        "        CFSc[j] += -((1/3)*confidence_factor_array_2[i][j])\n",
        "      else:\n",
        "        RSc[j] += PcR\n",
        "        CFSc[j] += -((1/3)*PcCF)\n",
        "\n",
        "      if j in indices_3:\n",
        "        RSc[j] += item_3[j]\n",
        "        CFSc[j] += -((1/3)*confidence_factor_array_3[i][j])\n",
        "      else:\n",
        "        RSc[j] += PcR\n",
        "        CFSc[j] += -((1/3)*PcCF)\n",
        "\n",
        "\n",
        "    CFSc_keys = [*CFSc]\n",
        "    # print(\"Keys:\", CFSc_keys)\n",
        "    # for key in CFSc_keys:\n",
        "    #   CFSc[key] = (1 - CFSc[key])\n",
        "    # print(\"RSc: \", RSc)\n",
        "    # print(\"CFSc: \", CFSc)\n",
        "    valid_keys = list(set([*RSc]) & set([*CFSc]))\n",
        "    for key in valid_keys:\n",
        "      FSc[key]= RSc[key]* CFSc[key]\n",
        "    # print(\"FSc: \", FSc)\n",
        "    predicted_class = min(FSc, key=FSc.get)\n",
        "    Y_Pred.append(predicted_class)\n",
        "  return np.asarray(Y_Pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WvGxNeI5KFbl"
      },
      "source": [
        "def PredictClass_2(merged_fuzzy_rank_array_1, merged_fuzzy_rank_array_2, confidence_factor_array_1, confidence_factor_array_2):  \n",
        "\n",
        "  Y_Pred = []\n",
        "  RSc = {}\n",
        "  CFSc = {}\n",
        "  FSc = {}\n",
        "  k = 3#int((fuzzy_rank_array_1.shape[1])/2);\n",
        "  PcR = 0.888\n",
        "  PcCF = 0\n",
        "    \n",
        "  for i in range(0, len(fuzzy_rank_array_1)):\n",
        "    item_1 = merged_fuzzy_rank_array_1[i]\n",
        "    item_2 = merged_fuzzy_rank_array_2[i]\n",
        "    indices_1 = sorted(range(len(item_1)), key=lambda x: item_1[x])[0:k]\n",
        "    indices_2 = sorted(range(len(item_2)), key=lambda x: item_2[x])[0:k]\n",
        "\n",
        "    for j in range(0, len(item_1)):\n",
        "      if j in indices_1:\n",
        "        RSc[j] = item_1[j]\n",
        "        CFSc[j] = 1-((1/2)*confidence_factor_array_1[i][j])\n",
        "      else:\n",
        "        RSc[j] = PcR\n",
        "        CFSc[j] = 1-((1/2)*PcCF)\n",
        "      \n",
        "      if j in indices_2:\n",
        "        RSc[j] += item_2[j]\n",
        "        CFSc[j] += -((1/2)*confidence_factor_array_2[i][j])\n",
        "      else:\n",
        "        RSc[j] += PcR\n",
        "        CFSc[j] += -((1/2)*PcCF)\n",
        "\n",
        "    CFSc_keys = [*CFSc]\n",
        "    # print(\"Keys:\", CFSc_keys)\n",
        "    # for key in CFSc_keys:\n",
        "    #   CFSc[key] = (1 - CFSc[key])\n",
        "    # print(\"RSc: \", RSc)\n",
        "    # print(\"CFSc: \", CFSc)\n",
        "    valid_keys = list(set([*RSc]) & set([*CFSc]))\n",
        "    for key in valid_keys:\n",
        "      FSc[key]= RSc[key]* CFSc[key]\n",
        "    # print(\"FSc: \", FSc)\n",
        "    predicted_class = min(FSc, key=FSc.get)\n",
        "    Y_Pred.append(predicted_class)\n",
        "  return np.asarray(Y_Pred)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I-R2SjwPhp-L"
      },
      "source": [
        "# Functions\n",
        "from math import exp\n",
        "from math import log\n",
        "    \n",
        "def mitcherlich(time, alpha, beta, rate):\n",
        "    \"\"\"\n",
        "    time : time\n",
        "    alpha : upper asymptote\n",
        "    beta : growth range\n",
        "    rate : growth rate\n",
        "    \"\"\"\n",
        "    result = alpha - beta * rate ** time\n",
        "    return result\n",
        "\n",
        "def blumberg(time, alpha, slope, w0=1):\n",
        "    \"\"\"\n",
        "    time : time\n",
        "    alpha : upper asymptote\n",
        "    w0 : a reference value at time = time_0\n",
        "    slope : slope of growth\n",
        "    \"\"\"\n",
        "    result = (alpha * (time) ** slope) / (w0 + (time) ** slope)\n",
        "    return result\n",
        "\n",
        "def gompertz(time, alpha, beta, rate):\n",
        "    \"\"\"\n",
        "    time : time\n",
        "    alpha : upper asymptote\n",
        "    beta : growth displacement\n",
        "    rate : growth rate\n",
        "    \"\"\"\n",
        "    result = alpha * exp(-beta * exp(-rate * time))\n",
        "    return result\n",
        "\n",
        "def weibull(time, alpha, beta, rate, slope):\n",
        "    \"\"\"\n",
        "    time : time\n",
        "    alpha : upper asymptote\n",
        "    beta : growth displacement\n",
        "    rate : growth rate\n",
        "    slope : slope of growth\n",
        "    \"\"\"\n",
        "    result = alpha - beta * exp(-rate * time ** slope)\n",
        "    return result\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TRB976WQhslM"
      },
      "source": [
        "def GenerateFuzzyRank_Gaussian(confidence_factor_array):  \n",
        "  fuzzy_rank_list = []\n",
        "  for item in confidence_factor_array:\n",
        "    arr=[]\n",
        "    for confidence_factor in item:\n",
        "      fuzzy_rank = 1-math.exp(((confidence_factor-1.0)*(confidence_factor-1.0)/(-2.0)))\n",
        "      arr.append(fuzzy_rank)\n",
        "    fuzzy_rank_list.append(arr)\n",
        "  return np.asarray(fuzzy_rank_list)\n",
        "\n",
        "def GenerateFuzzyRank_Mitcherlich(confidence_factor_array):  \n",
        "  fuzzy_rank_list = []\n",
        "  for item in confidence_factor_array:\n",
        "    arr=[]\n",
        "    for confidence_factor in item:\n",
        "      fuzzy_rank = mitcherlich(confidence_factor,2,1,2)\n",
        "      arr.append(fuzzy_rank)\n",
        "    fuzzy_rank_list.append(arr)\n",
        "  return np.asarray(fuzzy_rank_list)\n",
        "\n",
        "def GenerateFuzzyRank_Blumberg(confidence_factor_array):  \n",
        "  fuzzy_rank_list = []\n",
        "  for item in confidence_factor_array:\n",
        "    arr=[]\n",
        "    for confidence_factor in item:\n",
        "      fuzzy_rank = 1 - blumberg(confidence_factor, 1, 0.0001, w0=0.5)\n",
        "      arr.append(fuzzy_rank)\n",
        "    fuzzy_rank_list.append(arr)\n",
        "  return np.asarray(fuzzy_rank_list)\n",
        "\n",
        "def GenerateFuzzyRank_Gompertz(confidence_factor_array):  \n",
        "  fuzzy_rank_list = []\n",
        "  for item in confidence_factor_array:\n",
        "    arr=[]\n",
        "    for confidence_factor in item:\n",
        "      fuzzy_rank = 1 - gompertz(confidence_factor, 1, 2, 3)\n",
        "      arr.append(fuzzy_rank)\n",
        "    fuzzy_rank_list.append(arr)\n",
        "  return np.asarray(fuzzy_rank_list)\n",
        "\n",
        "def GenerateFuzzyRank_Weibull(confidence_factor_array):  \n",
        "  fuzzy_rank_list = []\n",
        "  for item in confidence_factor_array:\n",
        "    arr=[]\n",
        "    for confidence_factor in item:\n",
        "      fuzzy_rank = -weibull(confidence_factor, 0, 0.5, 2, 2) # We negate this \n",
        "      arr.append(fuzzy_rank)\n",
        "    fuzzy_rank_list.append(arr)\n",
        "  return np.asarray(fuzzy_rank_list)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1YLufwxAZwcR"
      },
      "source": [
        "def MergeFuzzyRanks(fuzzy_rank_array_1, fuzzy_rank_array_2, fuzzy_rank_array_3, fuzzy_rank_array_4, fuzzy_rank_array_5, confidence_factor_array):\n",
        "  k = 3\n",
        "  merged_fuzzy_rank_array = []\n",
        "  for i in range(len(fuzzy_rank_array_1)):\n",
        "    combined_fuzzy_scores = []\n",
        "    topKindices = set(sorted(range(len(confidence_factor_array[i])), key=lambda x: confidence_factor_array[i][x])[len(confidence_factor_array)-k-1:-1])\n",
        "    # set_topKindices = set(topKindices)\n",
        "    for j in range(len(fuzzy_rank_array_1[i])):  \n",
        "      if j in topKindices:\n",
        "        fuzzy_score = min(fuzzy_rank_array_1[i][j], fuzzy_rank_array_2[i][j], fuzzy_rank_array_3[i][j], fuzzy_rank_array_4[i][j], fuzzy_rank_array_5[i][j])\n",
        "        # print(\"Fuzzy Score: \", fuzzy_score)\n",
        "      else:\n",
        "        fuzzy_score = max(fuzzy_rank_array_1[i][j], fuzzy_rank_array_2[i][j], fuzzy_rank_array_3[i][j], fuzzy_rank_array_4[i][j], fuzzy_rank_array_5[i][j])\n",
        "        # print(\"Fuzzy Score: \", fuzzy_score)\n",
        "      combined_fuzzy_scores.append(fuzzy_score)\n",
        "    # print(\"Combined Fuzzy: \", combined_fuzzy_scores)\n",
        "    merged_fuzzy_rank_array.append(combined_fuzzy_scores)\n",
        "  return np.asarray(merged_fuzzy_rank_array)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5wVBVb8Vpn79"
      },
      "source": [
        "# # For ensembles (except Opportunity): -- Uncomment and Test!!\n",
        "\n",
        "# if __name__ == \"__main__\":  \n",
        "#   X,Y,folds = DataPreparation('/content/drive/MyDrive/data/SNOW/WISDM.npz')\n",
        "#   clf1 = DTC()\n",
        "#   clf2 = KNC()\n",
        "#   clf3 = LRC()\n",
        "#   clf4 = RForest()\n",
        "#   clf5 = AdaBoost()\n",
        "#   clf6 = RBFC()\n",
        "\n",
        "#   avg_acc_list = []\n",
        "#   avg_recall_list = []\n",
        "#   avg_f1_list = []\n",
        "\n",
        "#   for i in range(len(folds)):\n",
        "#     Train_idx = folds[i][0]\n",
        "#     Test_idx = folds[i][1]\n",
        "#     # X_Train_nonnormalized = X[Train_idx]\n",
        "#     X_Train = X[Train_idx]\n",
        "#     Y_Train = Y[Train_idx]\n",
        "#     # X_Test_nonnormalized = X[Test_idx]\n",
        "#     X_Test = X[Test_idx]\n",
        "#     Y_Test = Y[Test_idx]\n",
        "\n",
        "#     X_Train = feature_extraction(X_Train)\n",
        "#     # X_Train = preprocessing.normalize(X_Train_nonnormalized, norm='l2')\n",
        "#     X_Test = feature_extraction(X_Test)\n",
        "#     # X_Test = preprocessing.normalize(X_Test_nonnormalized, norm='l2')\n",
        "\n",
        "#     ## Train_idx = folds[i][0]\n",
        "#     ## Test_idx = folds[i][1]\n",
        "#     ## X_Train = X[Train_idx]\n",
        "#     ## Y_Train = Y[Train_idx]\n",
        "#     ## X_Test = X[Test_idx]\n",
        "#     ## Y_Test = Y[Test_idx]\n",
        "#     ## print(X_Test.shape[0])\n",
        "#     ## X_Train = feature_extraction(X_Train)\n",
        "#     ## X_Test = feature_extraction(X_Test)\n",
        "\n",
        "#     # For classifier 1\n",
        "#     confidence_factor_array_1, Y_Test = Train(X_Train, Y_Train, X_Test, Y_Test, clf1)\n",
        "#     fuzzy_rank_array_1 = GenerateFuzzyRank_Gaussian(confidence_factor_array_1)\n",
        "#     fuzzy_rank_array_2 = GenerateFuzzyRank_Mitcherlich(confidence_factor_array_1)\n",
        "#     fuzzy_rank_array_3 = GenerateFuzzyRank_Blumberg(confidence_factor_array_1)\n",
        "#     fuzzy_rank_array_4 = GenerateFuzzyRank_Gompertz(confidence_factor_array_1)\n",
        "#     fuzzy_rank_array_5 = GenerateFuzzyRank_Weibull(confidence_factor_array_1)\n",
        "\n",
        "#     # print(fuzzy_rank_array_1[0])\n",
        "#     # print(fuzzy_rank_array_2[0])\n",
        "#     # print(fuzzy_rank_array_3[0])\n",
        "#     # print(fuzzy_rank_array_4[0])\n",
        "#     # print(fuzzy_rank_array_5[0])\n",
        "#     # print(confidence_factor_array_1)\n",
        "#     # break\n",
        "\n",
        "#     ######\n",
        "#     # print(\"\\nCLASSIFIER 1\")\n",
        "#     # for row in fuzzy_rank_array_1:\n",
        "#     #   print(\"Gaussian: \",row)\n",
        "#     #   break\n",
        "      \n",
        "#     # for row in fuzzy_rank_array_2:\n",
        "#     #   print(\"Mitcherlich: \",row)\n",
        "#     #   break\n",
        "      \n",
        "#     # for row in fuzzy_rank_array_3:\n",
        "#     #   print(\"Blumberg: \",row)\n",
        "#     #   break\n",
        "      \n",
        "#     # for row in fuzzy_rank_array_4:\n",
        "#     #   print(\"Gompertz: \",row)\n",
        "#     #   break\n",
        "      \n",
        "#     # for row in fuzzy_rank_array_5:\n",
        "#     #   print(\"Weibull: \",row)\n",
        "#     #   break\n",
        "#     ######\n",
        "     \n",
        "    \n",
        "#     # print(\"Gaussian: \", fuzzy_rank_array_1)\n",
        "#     # print(\"Mitcherlich: \", fuzzy_rank_array_2)\n",
        "#     # print(\"Blumberg: \",fuzzy_rank_array_3)\n",
        "#     # print(\"Gompertz: \", fuzzy_rank_array_4)\n",
        "#     # print(\"Richard: \", fuzzy_rank_array_5)\n",
        "#     # print(\"\\n\")\n",
        "\n",
        "\n",
        "#     merged_fuzzy_rank_array_1 = MergeFuzzyRanks(fuzzy_rank_array_1, fuzzy_rank_array_2, fuzzy_rank_array_3, \n",
        "#                                               fuzzy_rank_array_4, fuzzy_rank_array_5, confidence_factor_array_1)\n",
        "#     # print(\"Merged Fuzzy Matrix: \", merged_fuzzy_rank_array_1)\n",
        "\n",
        "  \n",
        "#     # For classifier 2\n",
        "#     confidence_factor_array_2, Y_Test = Train(X_Train, Y_Train, X_Test, Y_Test, clf2)\n",
        "#     fuzzy_rank_array_6 = GenerateFuzzyRank_Gaussian(confidence_factor_array_2)\n",
        "#     fuzzy_rank_array_7 = GenerateFuzzyRank_Mitcherlich(confidence_factor_array_2)\n",
        "#     fuzzy_rank_array_8 = GenerateFuzzyRank_Blumberg(confidence_factor_array_2)\n",
        "#     fuzzy_rank_array_9 = GenerateFuzzyRank_Gompertz(confidence_factor_array_2)\n",
        "#     fuzzy_rank_array_10 = GenerateFuzzyRank_Weibull(confidence_factor_array_2)\n",
        "    \n",
        "#     ######\n",
        "#     # print(\"\\nCLASSIFIER 2\")\n",
        "#     # for row in fuzzy_rank_array_6:\n",
        "#     #   print(\"Gaussian: \",row)\n",
        "#     #   break\n",
        "      \n",
        "#     # for row in fuzzy_rank_array_7:\n",
        "#     #   print(\"Mitcherlich: \",row)\n",
        "#     #   break\n",
        "     \n",
        "#     # for row in fuzzy_rank_array_8:\n",
        "#     #   print(\"Blumberg: \",row)\n",
        "#     #   break\n",
        "      \n",
        "#     # for row in fuzzy_rank_array_9:\n",
        "#     #   print(\"Gompertz: \",row)\n",
        "#     #   break\n",
        "     \n",
        "#     # for row in fuzzy_rank_array_10:\n",
        "#     #   print(\"Weibull: \",row)\n",
        "#     #   break\n",
        "#     ######\n",
        "      \n",
        "\n",
        "#     # print(\"Gaussian: \", fuzzy_rank_array_6)\n",
        "#     # print(\"Mitcherlich: \", fuzzy_rank_array_7)\n",
        "#     # print(\"Blumberg: \",fuzzy_rank_array_8)\n",
        "#     # print(\"Gompertz: \", fuzzy_rank_array_9)\n",
        "#     # print(\"Richard: \", fuzzy_rank_array_10)\n",
        "#     # print(\"\\n\")\n",
        "\n",
        "#     merged_fuzzy_rank_array_2 = MergeFuzzyRanks(fuzzy_rank_array_6, fuzzy_rank_array_7, fuzzy_rank_array_8, \n",
        "#                                               fuzzy_rank_array_9, fuzzy_rank_array_10, confidence_factor_array_2)\n",
        "#     # print(\"Merged Fuzzy Matrix: \", merged_fuzzy_rank_array_2)\n",
        "\n",
        "\n",
        "    \n",
        "#     # For classifier 3\n",
        "#     confidence_factor_array_3, Y_Test = Train(X_Train, Y_Train, X_Test, Y_Test, clf6)\n",
        "#     fuzzy_rank_array_11 = GenerateFuzzyRank_Gaussian(confidence_factor_array_3)\n",
        "#     fuzzy_rank_array_12 = GenerateFuzzyRank_Mitcherlich(confidence_factor_array_3)\n",
        "#     fuzzy_rank_array_13 = GenerateFuzzyRank_Blumberg(confidence_factor_array_3)\n",
        "#     fuzzy_rank_array_14 = GenerateFuzzyRank_Gompertz(confidence_factor_array_3)\n",
        "#     fuzzy_rank_array_15 = GenerateFuzzyRank_Weibull(confidence_factor_array_3)\n",
        "    \n",
        "#     ######\n",
        "#     # print(\"\\nCLASSIFIER 3\")\n",
        "#     # for row in fuzzy_rank_array_11:\n",
        "#     #   print(\"Gaussian: \",row)\n",
        "#     #   break\n",
        "      \n",
        "#     # for row in fuzzy_rank_array_12:\n",
        "#     #   print(\"Mitcherlich: \",row)\n",
        "#     #   break\n",
        "     \n",
        "#     # for row in fuzzy_rank_array_13:\n",
        "#     #   print(\"Blumberg: \",row)\n",
        "#     #   break\n",
        "      \n",
        "#     # for row in fuzzy_rank_array_14:\n",
        "#     #   print(\"Gompertz: \",row)\n",
        "#     #   break\n",
        "      \n",
        "#     # for row in fuzzy_rank_array_15:\n",
        "#     #   print(\"Weibull: \",row)\n",
        "#     #   break\n",
        "#     ######\n",
        "      \n",
        "#     # print(\"Gaussian: \", fuzzy_rank_array_11)\n",
        "#     # print(\"Mitcherlich: \", fuzzy_rank_array_12)\n",
        "#     # print(\"Blumberg: \",fuzzy_rank_array_13)\n",
        "#     # print(\"Gompertz: \", fuzzy_rank_array_14)\n",
        "#     # print(\"Richard: \", fuzzy_rank_array_15)\n",
        "#     # print(\"\\n\")\n",
        "\n",
        "\n",
        "#     merged_fuzzy_rank_array_3 = MergeFuzzyRanks(fuzzy_rank_array_11, fuzzy_rank_array_12, fuzzy_rank_array_13, \n",
        "#                                               fuzzy_rank_array_14, fuzzy_rank_array_15, confidence_factor_array_3)\n",
        "#     # print(\"Merged Fuzzy Matrix: \", merged_fuzzy_rank_array_3)\n",
        "\n",
        "\n",
        "    \n",
        "#     # # For classifier 4\n",
        "#     # confidence_factor_array_4, Y_Test = Train(X_Train, Y_Train, X_Test, Y_Test, clf5)\n",
        "#     # fuzzy_rank_array_4 = GenerateFuzzyRank(confidence_factor_array_4)\n",
        "\n",
        "#     # # For classifier 5\n",
        "#     # confidence_factor_array_5, Y_Test = Train(X_Train, Y_Train, X_Test, Y_Test, clf5)\n",
        "#     # fuzzy_rank_array_5 = GenerateFuzzyRank(confidence_factor_array_5)\n",
        "\n",
        "\n",
        "#     # Ensembling all\n",
        "#     ## For 5 classifiers\n",
        "#     # Y_Pred = PredictClass_5(fuzzy_rank_array_1, fuzzy_rank_array_2, fuzzy_rank_array_3, fuzzy_rank_array_4, fuzzy_rank_array_5, \n",
        "#     #                      confidence_factor_array_1, confidence_factor_array_2, confidence_factor_array_3, confidence_factor_array_4, confidence_factor_array_5)\n",
        "#     ## For 3 classifiers\n",
        "#     Y_Pred = PredictClass_3(merged_fuzzy_rank_array_1, merged_fuzzy_rank_array_2, merged_fuzzy_rank_array_3,\n",
        "#                         confidence_factor_array_1, confidence_factor_array_2, confidence_factor_array_3)\n",
        "\n",
        "\n",
        "#     # Results\n",
        "#     # Correct = 0\n",
        "#     # Wrong = 0\n",
        "\n",
        "#     # for i in range(len(Y_Test)):\n",
        "#     #   if Y_Test[i] == Y_Pred[i]:\n",
        "#     #     Correct += 1\n",
        "#     #   else:\n",
        "#     #     Wrong += 1\n",
        "\n",
        "\n",
        "#     ## Do Comment this break\n",
        "#     # print(\"Actual Class: \", Y_Test[i])\n",
        "#     # break\n",
        "\n",
        "    \n",
        "\n",
        "#     # Uncomment for Test\n",
        "#     acc_fold = accuracy_score(Y_Test, Y_Pred)\n",
        "#     avg_acc_list.append(acc_fold)\n",
        "#     recall_fold = recall_score(Y_Test, Y_Pred, average='macro')\n",
        "#     avg_recall_list.append(recall_fold)\n",
        "#     f1_fold  = f1_score(Y_Test, Y_Pred, average='macro')\n",
        "#     avg_f1_list.append(f1_fold)\n",
        "\n",
        "#     # print(\"*************Correct: \",Correct,\"Wrong: \",Wrong,\"Accuracy: \", metrics.accuracy_score(Y_Test, Y_Pred)*100)\n",
        "#     # avg_acc.append((Correct*100)/(Correct+Wrong))\n",
        "#     print('Accuracy[{:.4f}] Recall[{:.4f}] F1[{:.4f}]'.format(acc_fold, recall_fold, f1_fold ,i+1))\n",
        "#     print('________________________________________________________________')\n",
        "\n",
        "#   avg_acc = np.asarray(avg_acc_list)\n",
        "#   avg_recall = np.asarray(avg_recall_list)\n",
        "#   avg_f1 = np.asarray(avg_f1_list)\n",
        "#   # print(\"\\nOverall Accuracy: \", sum(avg_acc)/len(avg_acc))\n",
        "#   print(\"\\n\")\n",
        "#   print('Overall Accuracy[{:.4f}] Overall Recall[{:.4f}] Overall F1[{:.4f}]'.format(np.mean(avg_acc), np.mean(avg_recall), np.mean(avg_f1)))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "anTeaeGC9r-M"
      },
      "source": [
        "# # Code for testing single ML classifiers -- Uncomment and Test!!!!\n",
        "\n",
        "# if __name__ == \"__main__\":  \n",
        "#   X,Y,folds = DataPreparation('/content/drive/MyDrive/SNOW/WISDM.npz')\n",
        "#   clf1 = DTC()\n",
        "#   clf2 = KNC()\n",
        "#   clf3 = LRC()\n",
        "#   clf4 = RForest()\n",
        "#   clf5 = AdaBoost()\n",
        "#   clf6 = RBFC()\n",
        "\n",
        "#   avg_acc_list = []\n",
        "#   avg_recall_list = []\n",
        "#   avg_f1_list = []\n",
        "\n",
        "#   clf = RBFC()\n",
        "\n",
        "#   avg_acc_list = []\n",
        "#   avg_recall_list = []\n",
        "#   avg_f1_list = []\n",
        "\n",
        "#   for i in range(len(folds)):\n",
        "#     Train_idx = folds[i][0]\n",
        "#     Test_idx = folds[i][1]\n",
        "#     X_Train_nonnormalized = X[Train_idx]\n",
        "#     Y_Train = Y[Train_idx]\n",
        "#     X_Test_nonnormalized = X[Test_idx]\n",
        "#     Y_Test = Y[Test_idx]\n",
        "\n",
        "#     X_Train_nonnormalized = feature_extraction(X_Train_nonnormalized)\n",
        "#     X_Train = preprocessing.normalize(X_Train_nonnormalized, norm='l1')\n",
        "#     X_Test_nonnormalized = feature_extraction(X_Test_nonnormalized)\n",
        "#     X_Test = preprocessing.normalize(X_Test_nonnormalized, norm='l1')\n",
        "\n",
        "\n",
        "#     clf.fit(X_Train, Y_Train)\n",
        "#     f1 = clf.predict(X_Test)  \n",
        "\n",
        "#     acc_fold = accuracy_score(Y_Test, f1)\n",
        "#     avg_acc_list.append(acc_fold)\n",
        "#     recall_fold = recall_score(Y_Test, f1, average='macro')\n",
        "#     avg_recall_list.append(recall_fold)\n",
        "#     f1_fold  = f1_score(Y_Test, f1, average='macro')\n",
        "#     avg_f1_list.append(f1_fold)\n",
        "\n",
        "#     # print(\"*************Correct: \",Correct,\"Wrong: \",Wrong,\"Accuracy: \", metrics.accuracy_score(Y_Test, Y_Pred)*100)\n",
        "#     # avg_acc.append((Correct*100)/(Correct+Wrong))\n",
        "#     print('Accuracy[{:.4f}] Recall[{:.4f}] F1[{:.4f}]'.format(acc_fold, recall_fold, f1_fold ,i+1))\n",
        "#     print('________________________________________________________________')\n",
        "\n",
        "#   avg_acc = np.asarray(avg_acc_list)\n",
        "#   avg_recall = np.asarray(avg_recall_list)\n",
        "#   avg_f1 = np.asarray(avg_f1_list)\n",
        "#   # print(\"\\nOverall Accuracy: \", sum(avg_acc)/len(avg_acc))\n",
        "#   print(\"\\n\")\n",
        "#   print('Overall Accuracy[{:.4f}] Overall Recall[{:.4f}] Overall F1[{:.4f}]'.format(np.mean(avg_acc), np.mean(avg_recall), np.mean(avg_f1)))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KI7WnZ95ATBV"
      },
      "source": [
        "# # Code for testing ensembled DNN classifiers -- Uncomment and Test!!!!\n",
        "\n",
        "# if __name__ == \"__main__\":  \n",
        "#   X,y,folds,n_class = DataPreparation_DNN('/content/drive/MyDrive/data/SNOW/WHARF.npz')\n",
        "\n",
        "#   avg_acc_list = []\n",
        "#   avg_recall_list = []\n",
        "#   avg_f1_list = []\n",
        "\n",
        "#   for i in range(0, len(folds)):\n",
        "#     train_idx = folds[i][0]\n",
        "#     test_idx = folds[i][1]\n",
        "#     X_train = X[train_idx]\n",
        "#     X_test = X[test_idx]\n",
        "#     y_train = y[train_idx]\n",
        "#     y_test = y[test_idx]\n",
        "\n",
        "#     # For classifier 1\n",
        "#     confidence_factor_array_1 = Train_JGH(X, y, X_train, X_test, y_train, y_test, n_class)\n",
        "#     fuzzy_rank_array_1 = GenerateFuzzyRank_Gaussian(confidence_factor_array_1)\n",
        "#     fuzzy_rank_array_2 = GenerateFuzzyRank_Mitcherlich(confidence_factor_array_1)\n",
        "#     fuzzy_rank_array_3 = GenerateFuzzyRank_Blumberg(confidence_factor_array_1)\n",
        "#     fuzzy_rank_array_4 = GenerateFuzzyRank_Gompertz(confidence_factor_array_1)\n",
        "#     fuzzy_rank_array_5 = GenerateFuzzyRank_Weibull(confidence_factor_array_1)\n",
        "\n",
        "#     merged_fuzzy_rank_array_1 = MergeFuzzyRanks(fuzzy_rank_array_1, fuzzy_rank_array_2, fuzzy_rank_array_3, \n",
        "#                                               fuzzy_rank_array_4, fuzzy_rank_array_5, confidence_factor_array_1)\n",
        "    \n",
        "\n",
        "\n",
        "#     # For classifier 2\n",
        "#     confidence_factor_array_2 = Train_Lyu(X, y, X_train, X_test, y_train, y_test, n_class)\n",
        "#     fuzzy_rank_array_6 = GenerateFuzzyRank_Gaussian(confidence_factor_array_2)\n",
        "#     fuzzy_rank_array_7 = GenerateFuzzyRank_Mitcherlich(confidence_factor_array_2)\n",
        "#     fuzzy_rank_array_8 = GenerateFuzzyRank_Blumberg(confidence_factor_array_2)\n",
        "#     fuzzy_rank_array_9 = GenerateFuzzyRank_Gompertz(confidence_factor_array_2)\n",
        "#     fuzzy_rank_array_10 = GenerateFuzzyRank_Weibull(confidence_factor_array_2)\n",
        "\n",
        "#     merged_fuzzy_rank_array_2 = MergeFuzzyRanks(fuzzy_rank_array_6, fuzzy_rank_array_7, fuzzy_rank_array_8, \n",
        "#                                               fuzzy_rank_array_9, fuzzy_rank_array_10, confidence_factor_array_2)\n",
        "\n",
        "\n",
        "    \n",
        "#     # For classifier 3\n",
        "#     confidence_factor_array_3 = Train_ResNet(X, y, X_train, X_test, y_train, y_test, n_class)\n",
        "#     fuzzy_rank_array_11 = GenerateFuzzyRank_Gaussian(confidence_factor_array_3)\n",
        "#     fuzzy_rank_array_12 = GenerateFuzzyRank_Mitcherlich(confidence_factor_array_3)\n",
        "#     fuzzy_rank_array_13 = GenerateFuzzyRank_Blumberg(confidence_factor_array_3)\n",
        "#     fuzzy_rank_array_14 = GenerateFuzzyRank_Gompertz(confidence_factor_array_3)\n",
        "#     fuzzy_rank_array_15 = GenerateFuzzyRank_Weibull(confidence_factor_array_3)\n",
        "\n",
        "#     merged_fuzzy_rank_array_3 = MergeFuzzyRanks(fuzzy_rank_array_11, fuzzy_rank_array_12, fuzzy_rank_array_13, \n",
        "#                                               fuzzy_rank_array_14, fuzzy_rank_array_15, confidence_factor_array_3)\n",
        "\n",
        "\n",
        "\n",
        "#     y_pred = PredictClass_3(merged_fuzzy_rank_array_1, merged_fuzzy_rank_array_2, merged_fuzzy_rank_array_3,\n",
        "#                             confidence_factor_array_1, confidence_factor_array_2, confidence_factor_array_3)\n",
        "\n",
        "#     # Correct format of y_test (becomes 1D)\n",
        "#     y_test = np.argmax(y_test, axis=1)\n",
        "\n",
        "#     # Uncomment for Test\n",
        "#     acc_fold = accuracy_score(y_test, y_pred)\n",
        "#     avg_acc_list.append(acc_fold)\n",
        "#     recall_fold = recall_score(y_test, y_pred, average='macro')\n",
        "#     avg_recall_list.append(recall_fold)\n",
        "#     f1_fold  = f1_score(y_test, y_pred, average='macro')\n",
        "#     avg_f1_list.append(f1_fold)\n",
        "\n",
        "#     # print(\"*************Correct: \",Correct,\"Wrong: \",Wrong,\"Accuracy: \", metrics.accuracy_score(Y_Test, Y_Pred)*100)\n",
        "#     # avg_acc.append((Correct*100)/(Correct+Wrong))\n",
        "#     print('Accuracy[{:.4f}] Recall[{:.4f}] F1[{:.4f}] at Fold[{}]'.format(acc_fold, recall_fold, f1_fold ,i+1))\n",
        "#     print('________________________________________________________________')\n",
        "\n",
        "#   avg_acc = np.asarray(avg_acc_list)\n",
        "#   avg_recall = np.asarray(avg_recall_list)\n",
        "#   avg_f1 = np.asarray(avg_f1_list)\n",
        "#   # print(\"\\nOverall Accuracy: \", sum(avg_acc)/len(avg_acc))\n",
        "#   print(\"\\n\")\n",
        "#   print('Overall Accuracy[{:.4f}] Overall Recall[{:.4f}] Overall F1[{:.4f}]'.format(np.mean(avg_acc), np.mean(avg_recall), np.mean(avg_f1)))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l99UOr__mMtI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8fd3493b-dea7-4961-f36a-35bb407f7bbc"
      },
      "source": [
        "# Code for testing Opportunity Dataset -- Uncomment and Test!!\n",
        "\n",
        "def OpportunityDataSetPreparation():\n",
        "  X_train=np.load('/content/drive/MyDrive/data/Opportunity/Opportunity_train_X.npz')['arr_0']\n",
        "  X_test=np.load('/content/drive/MyDrive/data/Opportunity/Opportunity_test_X.npz')['arr_0']\n",
        "  Y_train=np.load('/content/drive/MyDrive/data/Opportunity/Opportunity_train_y.npz')['arr_0']\n",
        "  Y_test=np.load('/content/drive/MyDrive/data/Opportunity/Opportunity_test_Y.npz')['arr_0']\n",
        "  X = np.concatenate((X_train, X_test), axis = 0)\n",
        "  Y = np.concatenate((Y_train, Y_test), axis = 0)\n",
        "  classes_number = Y_train.shape[1]\n",
        "  return X, Y, X_train,Y_train,X_test,Y_test,classes_number\n",
        "\n",
        "\n",
        "X, Y, X_Train, Y_Train, X_Test, Y_Test, n_classes = OpportunityDataSetPreparation()\n",
        "#clf1 = DTC()\n",
        "#clf2 = KNC()\n",
        "#clf3 = LRC()\n",
        "#clf4 = RForest()\n",
        "#clf5 = AdaBoost()\n",
        "#clf6 = RBFC()\n",
        "#X_Train = feature_extraction(X_Train)\n",
        "#X_Train = preprocessing.normalize(X_Train_nonnormalized, norm='l1')\n",
        "#X_Test = feature_extraction(X_Test)\n",
        "#X_Test = preprocessing.normalize(X_Test_nonnormalized, norm='l1')\n",
        "\n",
        "\n",
        "# For classifier 1\n",
        "confidence_factor_array_1 = Train_Lyu_Opp(X, Y, X_Train, X_Test, Y_Train, Y_Test, n_classes)\n",
        "fuzzy_rank_array_1 = GenerateFuzzyRank_Gaussian(confidence_factor_array_1)\n",
        "fuzzy_rank_array_2 = GenerateFuzzyRank_Mitcherlich(confidence_factor_array_1)\n",
        "fuzzy_rank_array_3 = GenerateFuzzyRank_Blumberg(confidence_factor_array_1)\n",
        "fuzzy_rank_array_4 = GenerateFuzzyRank_Gompertz(confidence_factor_array_1)\n",
        "fuzzy_rank_array_5 = GenerateFuzzyRank_Weibull(confidence_factor_array_1)\n",
        "\n",
        "# print(fuzzy_rank_array_1[0])\n",
        "# print(fuzzy_rank_array_2[0])\n",
        "# print(fuzzy_rank_array_3[0])\n",
        "# print(fuzzy_rank_array_4[0])\n",
        "# print(fuzzy_rank_array_5[0])\n",
        "# print(confidence_factor_array_1)\n",
        "# break\n",
        "\n",
        "merged_fuzzy_rank_array_1 = MergeFuzzyRanks(fuzzy_rank_array_1, fuzzy_rank_array_2, fuzzy_rank_array_3, \n",
        "                                              fuzzy_rank_array_4, fuzzy_rank_array_5, confidence_factor_array_1)\n",
        "# print(\"Merged Fuzzy Matrix: \", merged_fuzzy_rank_array_1)\n",
        "\n",
        "  \n",
        "# For classifier 2\n",
        "confidence_factor_array_2 = Train_JGH_Opp(X, Y, X_Train, X_Test, Y_Train, Y_Test, n_classes)\n",
        "fuzzy_rank_array_6 = GenerateFuzzyRank_Gaussian(confidence_factor_array_2)\n",
        "fuzzy_rank_array_7 = GenerateFuzzyRank_Mitcherlich(confidence_factor_array_2)\n",
        "fuzzy_rank_array_8 = GenerateFuzzyRank_Blumberg(confidence_factor_array_2)\n",
        "fuzzy_rank_array_9 = GenerateFuzzyRank_Gompertz(confidence_factor_array_2)\n",
        "fuzzy_rank_array_10 = GenerateFuzzyRank_Weibull(confidence_factor_array_2)\n",
        "    \n",
        "merged_fuzzy_rank_array_2 = MergeFuzzyRanks(fuzzy_rank_array_6, fuzzy_rank_array_7, fuzzy_rank_array_8, \n",
        "                                              fuzzy_rank_array_9, fuzzy_rank_array_10, confidence_factor_array_2)\n",
        "# print(\"Merged Fuzzy Matrix: \", merged_fuzzy_rank_array_2)\n",
        "\n",
        "\n",
        "    \n",
        "# For classifier 3\n",
        "confidence_factor_array_3 = Train_ResNet_Opp(X, Y, X_Train, X_Test, Y_Train, Y_Test, n_classes)\n",
        "fuzzy_rank_array_11 = GenerateFuzzyRank_Gaussian(confidence_factor_array_3)\n",
        "fuzzy_rank_array_12 = GenerateFuzzyRank_Mitcherlich(confidence_factor_array_3)\n",
        "fuzzy_rank_array_13 = GenerateFuzzyRank_Blumberg(confidence_factor_array_3)\n",
        "fuzzy_rank_array_14 = GenerateFuzzyRank_Gompertz(confidence_factor_array_3)\n",
        "fuzzy_rank_array_15 = GenerateFuzzyRank_Weibull(confidence_factor_array_3)\n",
        "    \n",
        "merged_fuzzy_rank_array_3 = MergeFuzzyRanks(fuzzy_rank_array_11, fuzzy_rank_array_12, fuzzy_rank_array_13, \n",
        "                                              fuzzy_rank_array_14, fuzzy_rank_array_15, confidence_factor_array_3)\n",
        "# print(\"Merged Fuzzy Matrix: \", merged_fuzzy_rank_array_3)\n",
        "\n",
        "\n",
        "    \n",
        "    \n",
        "Y_Pred = PredictClass_3(merged_fuzzy_rank_array_1, merged_fuzzy_rank_array_2, merged_fuzzy_rank_array_3,\n",
        "                        confidence_factor_array_1, confidence_factor_array_2, confidence_factor_array_3)\n",
        "\n",
        "Y_Test = np.argmax(y_test, axis=1)    \n",
        "\n",
        "# Uncomment for Test\n",
        "avg_acc = accuracy_score(Y_Test, Y_Pred)\n",
        "avg_recall = recall_score(Y_Test, Y_Pred, average='macro')\n",
        "avg_f1 = f1_score(Y_Test, Y_Pred, average='macro')\n",
        "\n",
        "print('Overall Accuracy[{:.4f}] Overall Recall[{:.4f}] Overall F1[{:.4f}]'.format(avg_acc, avg_recall, avg_f1))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "364/364 - 6s - loss: 0.7757 - accuracy: 0.6673\n",
            "Epoch 2/200\n",
            "364/364 - 3s - loss: 0.5755 - accuracy: 0.7661\n",
            "Epoch 3/200\n",
            "364/364 - 3s - loss: 0.4786 - accuracy: 0.8150\n",
            "Epoch 4/200\n",
            "364/364 - 3s - loss: 0.4268 - accuracy: 0.8393\n",
            "Epoch 5/200\n",
            "364/364 - 3s - loss: 0.3913 - accuracy: 0.8550\n",
            "Epoch 6/200\n",
            "364/364 - 3s - loss: 0.3783 - accuracy: 0.8592\n",
            "Epoch 7/200\n",
            "364/364 - 3s - loss: 0.3576 - accuracy: 0.8661\n",
            "Epoch 8/200\n",
            "364/364 - 3s - loss: 0.3420 - accuracy: 0.8720\n",
            "Epoch 9/200\n",
            "364/364 - 3s - loss: 0.3345 - accuracy: 0.8750\n",
            "Epoch 10/200\n",
            "364/364 - 3s - loss: 0.3158 - accuracy: 0.8822\n",
            "Epoch 11/200\n",
            "364/364 - 3s - loss: 0.3121 - accuracy: 0.8830\n",
            "Epoch 12/200\n",
            "364/364 - 3s - loss: 0.3026 - accuracy: 0.8865\n",
            "Epoch 13/200\n",
            "364/364 - 3s - loss: 0.2935 - accuracy: 0.8902\n",
            "Epoch 14/200\n",
            "364/364 - 3s - loss: 0.2871 - accuracy: 0.8905\n",
            "Epoch 15/200\n",
            "364/364 - 3s - loss: 0.2923 - accuracy: 0.8904\n",
            "Epoch 16/200\n",
            "364/364 - 3s - loss: 0.2774 - accuracy: 0.8964\n",
            "Epoch 17/200\n",
            "364/364 - 3s - loss: 0.2705 - accuracy: 0.8984\n",
            "Epoch 18/200\n",
            "364/364 - 3s - loss: 0.2698 - accuracy: 0.8996\n",
            "Epoch 19/200\n",
            "364/364 - 3s - loss: 0.2580 - accuracy: 0.9027\n",
            "Epoch 20/200\n",
            "364/364 - 3s - loss: 0.2538 - accuracy: 0.9045\n",
            "Epoch 21/200\n",
            "364/364 - 3s - loss: 0.2582 - accuracy: 0.9024\n",
            "Epoch 22/200\n",
            "364/364 - 3s - loss: 0.2485 - accuracy: 0.9069\n",
            "Epoch 23/200\n",
            "364/364 - 3s - loss: 0.2445 - accuracy: 0.9082\n",
            "Epoch 24/200\n",
            "364/364 - 3s - loss: 0.2445 - accuracy: 0.9073\n",
            "Epoch 25/200\n",
            "364/364 - 3s - loss: 0.2371 - accuracy: 0.9121\n",
            "Epoch 26/200\n",
            "364/364 - 3s - loss: 0.2353 - accuracy: 0.9120\n",
            "Epoch 27/200\n",
            "364/364 - 3s - loss: 0.2236 - accuracy: 0.9153\n",
            "Epoch 28/200\n",
            "364/364 - 3s - loss: 0.2297 - accuracy: 0.9140\n",
            "Epoch 29/200\n",
            "364/364 - 3s - loss: 0.2253 - accuracy: 0.9158\n",
            "Epoch 30/200\n",
            "364/364 - 3s - loss: 0.2245 - accuracy: 0.9149\n",
            "Epoch 31/200\n",
            "364/364 - 3s - loss: 0.2179 - accuracy: 0.9181\n",
            "Epoch 32/200\n",
            "364/364 - 3s - loss: 0.2127 - accuracy: 0.9198\n",
            "Epoch 33/200\n",
            "364/364 - 3s - loss: 0.2094 - accuracy: 0.9216\n",
            "Epoch 34/200\n",
            "364/364 - 3s - loss: 0.2102 - accuracy: 0.9188\n",
            "Epoch 35/200\n",
            "364/364 - 3s - loss: 0.2110 - accuracy: 0.9198\n",
            "Epoch 36/200\n",
            "364/364 - 3s - loss: 0.2079 - accuracy: 0.9222\n",
            "Epoch 37/200\n",
            "364/364 - 3s - loss: 0.2078 - accuracy: 0.9207\n",
            "Epoch 38/200\n",
            "364/364 - 3s - loss: 0.1982 - accuracy: 0.9261\n",
            "Epoch 39/200\n",
            "364/364 - 3s - loss: 0.1975 - accuracy: 0.9250\n",
            "Epoch 40/200\n",
            "364/364 - 3s - loss: 0.1976 - accuracy: 0.9250\n",
            "Epoch 41/200\n",
            "364/364 - 3s - loss: 0.1991 - accuracy: 0.9242\n",
            "Epoch 42/200\n",
            "364/364 - 3s - loss: 0.1924 - accuracy: 0.9270\n",
            "Epoch 43/200\n",
            "364/364 - 3s - loss: 0.1822 - accuracy: 0.9315\n",
            "Epoch 44/200\n",
            "364/364 - 3s - loss: 0.1891 - accuracy: 0.9294\n",
            "Epoch 45/200\n",
            "364/364 - 3s - loss: 0.1881 - accuracy: 0.9292\n",
            "Epoch 46/200\n",
            "364/364 - 3s - loss: 0.1817 - accuracy: 0.9307\n",
            "Epoch 47/200\n",
            "364/364 - 3s - loss: 0.1849 - accuracy: 0.9296\n",
            "Epoch 48/200\n",
            "364/364 - 3s - loss: 0.1869 - accuracy: 0.9286\n",
            "Epoch 49/200\n",
            "364/364 - 3s - loss: 0.1809 - accuracy: 0.9312\n",
            "Epoch 50/200\n",
            "364/364 - 3s - loss: 0.1702 - accuracy: 0.9340\n",
            "Epoch 51/200\n",
            "364/364 - 3s - loss: 0.1746 - accuracy: 0.9343\n",
            "Epoch 52/200\n",
            "364/364 - 3s - loss: 0.1753 - accuracy: 0.9336\n",
            "Epoch 53/200\n",
            "364/364 - 3s - loss: 0.1673 - accuracy: 0.9362\n",
            "Epoch 54/200\n",
            "364/364 - 3s - loss: 0.1686 - accuracy: 0.9362\n",
            "Epoch 55/200\n",
            "364/364 - 3s - loss: 0.1679 - accuracy: 0.9357\n",
            "Epoch 56/200\n",
            "364/364 - 3s - loss: 0.1622 - accuracy: 0.9382\n",
            "Epoch 57/200\n",
            "364/364 - 3s - loss: 0.1628 - accuracy: 0.9385\n",
            "Epoch 58/200\n",
            "364/364 - 3s - loss: 0.1592 - accuracy: 0.9394\n",
            "Epoch 59/200\n",
            "364/364 - 3s - loss: 0.1617 - accuracy: 0.9396\n",
            "Epoch 60/200\n",
            "364/364 - 3s - loss: 0.1618 - accuracy: 0.9395\n",
            "Epoch 61/200\n",
            "364/364 - 3s - loss: 0.1581 - accuracy: 0.9398\n",
            "Epoch 62/200\n",
            "364/364 - 3s - loss: 0.1576 - accuracy: 0.9407\n",
            "Epoch 63/200\n",
            "364/364 - 3s - loss: 0.1508 - accuracy: 0.9416\n",
            "Epoch 64/200\n",
            "364/364 - 3s - loss: 0.1475 - accuracy: 0.9442\n",
            "Epoch 65/200\n",
            "364/364 - 3s - loss: 0.1533 - accuracy: 0.9432\n",
            "Epoch 66/200\n",
            "364/364 - 3s - loss: 0.1511 - accuracy: 0.9418\n",
            "Epoch 67/200\n",
            "364/364 - 3s - loss: 0.1465 - accuracy: 0.9436\n",
            "Epoch 68/200\n",
            "364/364 - 3s - loss: 0.1490 - accuracy: 0.9440\n",
            "Epoch 69/200\n",
            "364/364 - 3s - loss: 0.1459 - accuracy: 0.9447\n",
            "Epoch 70/200\n",
            "364/364 - 3s - loss: 0.1407 - accuracy: 0.9472\n",
            "Epoch 71/200\n",
            "364/364 - 3s - loss: 0.1434 - accuracy: 0.9450\n",
            "Epoch 72/200\n",
            "364/364 - 3s - loss: 0.1393 - accuracy: 0.9474\n",
            "Epoch 73/200\n",
            "364/364 - 3s - loss: 0.1409 - accuracy: 0.9469\n",
            "Epoch 74/200\n",
            "364/364 - 3s - loss: 0.1455 - accuracy: 0.9447\n",
            "Epoch 75/200\n",
            "364/364 - 3s - loss: 0.1382 - accuracy: 0.9482\n",
            "Epoch 76/200\n",
            "364/364 - 3s - loss: 0.1381 - accuracy: 0.9461\n",
            "Epoch 77/200\n",
            "364/364 - 3s - loss: 0.1360 - accuracy: 0.9489\n",
            "Epoch 78/200\n",
            "364/364 - 3s - loss: 0.1304 - accuracy: 0.9504\n",
            "Epoch 79/200\n",
            "364/364 - 3s - loss: 0.1305 - accuracy: 0.9500\n",
            "Epoch 80/200\n",
            "364/364 - 3s - loss: 0.1318 - accuracy: 0.9495\n",
            "Epoch 81/200\n",
            "364/364 - 3s - loss: 0.1269 - accuracy: 0.9513\n",
            "Epoch 82/200\n",
            "364/364 - 3s - loss: 0.1362 - accuracy: 0.9477\n",
            "Epoch 83/200\n",
            "364/364 - 3s - loss: 0.1290 - accuracy: 0.9507\n",
            "Epoch 84/200\n",
            "364/364 - 3s - loss: 0.1268 - accuracy: 0.9523\n",
            "Epoch 85/200\n",
            "364/364 - 3s - loss: 0.1247 - accuracy: 0.9528\n",
            "Epoch 86/200\n",
            "364/364 - 3s - loss: 0.1255 - accuracy: 0.9519\n",
            "Epoch 87/200\n",
            "364/364 - 3s - loss: 0.1222 - accuracy: 0.9540\n",
            "Epoch 88/200\n",
            "364/364 - 3s - loss: 0.1286 - accuracy: 0.9512\n",
            "Epoch 89/200\n",
            "364/364 - 3s - loss: 0.1185 - accuracy: 0.9545\n",
            "Epoch 90/200\n",
            "364/364 - 3s - loss: 0.1199 - accuracy: 0.9554\n",
            "Epoch 91/200\n",
            "364/364 - 3s - loss: 0.1202 - accuracy: 0.9551\n",
            "Epoch 92/200\n",
            "364/364 - 3s - loss: 0.1248 - accuracy: 0.9522\n",
            "Epoch 93/200\n",
            "364/364 - 3s - loss: 0.1184 - accuracy: 0.9551\n",
            "Epoch 94/200\n",
            "364/364 - 3s - loss: 0.1231 - accuracy: 0.9535\n",
            "Epoch 95/200\n",
            "364/364 - 3s - loss: 0.1112 - accuracy: 0.9580\n",
            "Epoch 96/200\n",
            "364/364 - 3s - loss: 0.1119 - accuracy: 0.9567\n",
            "Epoch 97/200\n",
            "364/364 - 3s - loss: 0.1139 - accuracy: 0.9562\n",
            "Epoch 98/200\n",
            "364/364 - 3s - loss: 0.1114 - accuracy: 0.9592\n",
            "Epoch 99/200\n",
            "364/364 - 3s - loss: 0.1100 - accuracy: 0.9583\n",
            "Epoch 100/200\n",
            "364/364 - 3s - loss: 0.1141 - accuracy: 0.9574\n",
            "Epoch 101/200\n",
            "364/364 - 3s - loss: 0.1060 - accuracy: 0.9599\n",
            "Epoch 102/200\n",
            "364/364 - 3s - loss: 0.1108 - accuracy: 0.9582\n",
            "Epoch 103/200\n",
            "364/364 - 3s - loss: 0.1077 - accuracy: 0.9584\n",
            "Epoch 104/200\n",
            "364/364 - 3s - loss: 0.1059 - accuracy: 0.9593\n",
            "Epoch 105/200\n",
            "364/364 - 3s - loss: 0.1109 - accuracy: 0.9589\n",
            "Epoch 106/200\n",
            "364/364 - 3s - loss: 0.0988 - accuracy: 0.9625\n",
            "Epoch 107/200\n",
            "364/364 - 3s - loss: 0.1077 - accuracy: 0.9595\n",
            "Epoch 108/200\n",
            "364/364 - 3s - loss: 0.1024 - accuracy: 0.9612\n",
            "Epoch 109/200\n",
            "364/364 - 3s - loss: 0.1046 - accuracy: 0.9595\n",
            "Epoch 110/200\n",
            "364/364 - 3s - loss: 0.1112 - accuracy: 0.9589\n",
            "Epoch 111/200\n",
            "364/364 - 3s - loss: 0.0945 - accuracy: 0.9641\n",
            "Epoch 112/200\n",
            "364/364 - 3s - loss: 0.1005 - accuracy: 0.9626\n",
            "Epoch 113/200\n",
            "364/364 - 3s - loss: 0.1059 - accuracy: 0.9607\n",
            "Epoch 114/200\n",
            "364/364 - 3s - loss: 0.0981 - accuracy: 0.9630\n",
            "Epoch 115/200\n",
            "364/364 - 3s - loss: 0.1028 - accuracy: 0.9614\n",
            "Epoch 116/200\n",
            "364/364 - 3s - loss: 0.0962 - accuracy: 0.9633\n",
            "Epoch 117/200\n",
            "364/364 - 3s - loss: 0.1003 - accuracy: 0.9619\n",
            "Epoch 118/200\n",
            "364/364 - 3s - loss: 0.0924 - accuracy: 0.9650\n",
            "Epoch 119/200\n",
            "364/364 - 3s - loss: 0.0974 - accuracy: 0.9626\n",
            "Epoch 120/200\n",
            "364/364 - 3s - loss: 0.0985 - accuracy: 0.9637\n",
            "Epoch 121/200\n",
            "364/364 - 3s - loss: 0.0943 - accuracy: 0.9648\n",
            "Epoch 122/200\n",
            "364/364 - 3s - loss: 0.0935 - accuracy: 0.9651\n",
            "Epoch 123/200\n",
            "364/364 - 3s - loss: 0.0964 - accuracy: 0.9635\n",
            "Epoch 124/200\n",
            "364/364 - 3s - loss: 0.0902 - accuracy: 0.9655\n",
            "Epoch 125/200\n",
            "364/364 - 3s - loss: 0.0890 - accuracy: 0.9672\n",
            "Epoch 126/200\n",
            "364/364 - 3s - loss: 0.0927 - accuracy: 0.9655\n",
            "Epoch 127/200\n",
            "364/364 - 3s - loss: 0.0918 - accuracy: 0.9654\n",
            "Epoch 128/200\n",
            "364/364 - 3s - loss: 0.0890 - accuracy: 0.9659\n",
            "Epoch 129/200\n",
            "364/364 - 3s - loss: 0.0881 - accuracy: 0.9658\n",
            "Epoch 130/200\n",
            "364/364 - 3s - loss: 0.0862 - accuracy: 0.9679\n",
            "Epoch 131/200\n",
            "364/364 - 3s - loss: 0.0862 - accuracy: 0.9673\n",
            "Epoch 132/200\n",
            "364/364 - 3s - loss: 0.0932 - accuracy: 0.9649\n",
            "Epoch 133/200\n",
            "364/364 - 3s - loss: 0.0892 - accuracy: 0.9659\n",
            "Epoch 134/200\n",
            "364/364 - 3s - loss: 0.0883 - accuracy: 0.9664\n",
            "Epoch 135/200\n",
            "364/364 - 3s - loss: 0.0815 - accuracy: 0.9687\n",
            "Epoch 136/200\n",
            "364/364 - 3s - loss: 0.0872 - accuracy: 0.9670\n",
            "Epoch 137/200\n",
            "364/364 - 3s - loss: 0.0809 - accuracy: 0.9690\n",
            "Epoch 138/200\n",
            "364/364 - 3s - loss: 0.0876 - accuracy: 0.9672\n",
            "Epoch 139/200\n",
            "364/364 - 3s - loss: 0.0808 - accuracy: 0.9692\n",
            "Epoch 140/200\n",
            "364/364 - 3s - loss: 0.0860 - accuracy: 0.9680\n",
            "Epoch 141/200\n",
            "364/364 - 3s - loss: 0.0829 - accuracy: 0.9685\n",
            "Epoch 142/200\n",
            "364/364 - 3s - loss: 0.0843 - accuracy: 0.9677\n",
            "Epoch 143/200\n",
            "364/364 - 3s - loss: 0.0840 - accuracy: 0.9683\n",
            "Epoch 144/200\n",
            "364/364 - 3s - loss: 0.0792 - accuracy: 0.9699\n",
            "Epoch 145/200\n",
            "364/364 - 3s - loss: 0.0782 - accuracy: 0.9707\n",
            "Epoch 146/200\n",
            "364/364 - 3s - loss: 0.0799 - accuracy: 0.9694\n",
            "Epoch 147/200\n",
            "364/364 - 3s - loss: 0.0809 - accuracy: 0.9684\n",
            "Epoch 148/200\n",
            "364/364 - 3s - loss: 0.0847 - accuracy: 0.9675\n",
            "Epoch 149/200\n",
            "364/364 - 3s - loss: 0.0736 - accuracy: 0.9732\n",
            "Epoch 150/200\n",
            "364/364 - 3s - loss: 0.0806 - accuracy: 0.9698\n",
            "Epoch 151/200\n",
            "364/364 - 3s - loss: 0.0718 - accuracy: 0.9728\n",
            "Epoch 152/200\n",
            "364/364 - 3s - loss: 0.0877 - accuracy: 0.9675\n",
            "Epoch 153/200\n",
            "364/364 - 3s - loss: 0.0774 - accuracy: 0.9708\n",
            "Epoch 154/200\n",
            "364/364 - 3s - loss: 0.0793 - accuracy: 0.9696\n",
            "Epoch 155/200\n",
            "364/364 - 3s - loss: 0.0746 - accuracy: 0.9720\n",
            "Epoch 156/200\n",
            "364/364 - 3s - loss: 0.0760 - accuracy: 0.9713\n",
            "Epoch 157/200\n",
            "364/364 - 3s - loss: 0.0744 - accuracy: 0.9723\n",
            "Epoch 158/200\n",
            "364/364 - 3s - loss: 0.0761 - accuracy: 0.9711\n",
            "Epoch 159/200\n",
            "364/364 - 3s - loss: 0.0780 - accuracy: 0.9711\n",
            "Epoch 160/200\n",
            "364/364 - 3s - loss: 0.0687 - accuracy: 0.9737\n",
            "Epoch 161/200\n",
            "364/364 - 3s - loss: 0.0706 - accuracy: 0.9729\n",
            "Epoch 162/200\n",
            "364/364 - 3s - loss: 0.0786 - accuracy: 0.9702\n",
            "Epoch 163/200\n",
            "364/364 - 3s - loss: 0.0734 - accuracy: 0.9724\n",
            "Epoch 164/200\n",
            "364/364 - 3s - loss: 0.0719 - accuracy: 0.9728\n",
            "Epoch 165/200\n",
            "364/364 - 3s - loss: 0.0701 - accuracy: 0.9740\n",
            "Epoch 166/200\n",
            "364/364 - 3s - loss: 0.0721 - accuracy: 0.9728\n",
            "Epoch 167/200\n",
            "364/364 - 3s - loss: 0.0722 - accuracy: 0.9734\n",
            "Epoch 168/200\n",
            "364/364 - 3s - loss: 0.0824 - accuracy: 0.9691\n",
            "Epoch 169/200\n",
            "364/364 - 3s - loss: 0.0678 - accuracy: 0.9753\n",
            "Epoch 170/200\n",
            "364/364 - 3s - loss: 0.0738 - accuracy: 0.9720\n",
            "Epoch 171/200\n",
            "364/364 - 3s - loss: 0.0731 - accuracy: 0.9723\n",
            "Epoch 172/200\n",
            "364/364 - 3s - loss: 0.0709 - accuracy: 0.9733\n",
            "Epoch 173/200\n",
            "364/364 - 3s - loss: 0.0692 - accuracy: 0.9743\n",
            "Epoch 174/200\n",
            "364/364 - 3s - loss: 0.0674 - accuracy: 0.9747\n",
            "Epoch 175/200\n",
            "364/364 - 3s - loss: 0.0813 - accuracy: 0.9688\n",
            "Epoch 176/200\n",
            "364/364 - 3s - loss: 0.0666 - accuracy: 0.9747\n",
            "Epoch 177/200\n",
            "364/364 - 3s - loss: 0.0636 - accuracy: 0.9761\n",
            "Epoch 178/200\n",
            "364/364 - 3s - loss: 0.0716 - accuracy: 0.9726\n",
            "Epoch 179/200\n",
            "364/364 - 3s - loss: 0.0603 - accuracy: 0.9779\n",
            "Epoch 180/200\n",
            "364/364 - 3s - loss: 0.0680 - accuracy: 0.9740\n",
            "Epoch 181/200\n",
            "364/364 - 3s - loss: 0.0670 - accuracy: 0.9749\n",
            "Epoch 182/200\n",
            "364/364 - 3s - loss: 0.0674 - accuracy: 0.9745\n",
            "Epoch 183/200\n",
            "364/364 - 3s - loss: 0.0672 - accuracy: 0.9751\n",
            "Epoch 184/200\n",
            "364/364 - 3s - loss: 0.0717 - accuracy: 0.9735\n",
            "Epoch 185/200\n",
            "364/364 - 3s - loss: 0.0676 - accuracy: 0.9747\n",
            "Epoch 186/200\n",
            "364/364 - 3s - loss: 0.0661 - accuracy: 0.9753\n",
            "Epoch 187/200\n",
            "364/364 - 3s - loss: 0.0690 - accuracy: 0.9743\n",
            "Epoch 188/200\n",
            "364/364 - 3s - loss: 0.0612 - accuracy: 0.9768\n",
            "Epoch 189/200\n",
            "364/364 - 3s - loss: 0.0661 - accuracy: 0.9761\n",
            "Epoch 190/200\n",
            "364/364 - 3s - loss: 0.0718 - accuracy: 0.9735\n",
            "Epoch 191/200\n",
            "364/364 - 3s - loss: 0.0619 - accuracy: 0.9761\n",
            "Epoch 192/200\n",
            "364/364 - 3s - loss: 0.0579 - accuracy: 0.9783\n",
            "Epoch 193/200\n",
            "364/364 - 3s - loss: 0.0617 - accuracy: 0.9768\n",
            "Epoch 194/200\n",
            "364/364 - 3s - loss: 0.0692 - accuracy: 0.9740\n",
            "Epoch 195/200\n",
            "364/364 - 3s - loss: 0.0555 - accuracy: 0.9797\n",
            "Epoch 196/200\n",
            "364/364 - 3s - loss: 0.0638 - accuracy: 0.9757\n",
            "Epoch 197/200\n",
            "364/364 - 3s - loss: 0.0628 - accuracy: 0.9758\n",
            "Epoch 198/200\n",
            "364/364 - 3s - loss: 0.0647 - accuracy: 0.9755\n",
            "Epoch 199/200\n",
            "364/364 - 3s - loss: 0.0645 - accuracy: 0.9758\n",
            "Epoch 200/200\n",
            "364/364 - 3s - loss: 0.0597 - accuracy: 0.9781\n",
            "Epoch 1/250\n",
            "243/243 - 7s - loss: 0.7094 - accuracy: 0.7159\n",
            "Epoch 2/250\n",
            "243/243 - 2s - loss: 0.5315 - accuracy: 0.7905\n",
            "Epoch 3/250\n",
            "243/243 - 2s - loss: 0.4747 - accuracy: 0.8163\n",
            "Epoch 4/250\n",
            "243/243 - 2s - loss: 0.4412 - accuracy: 0.8310\n",
            "Epoch 5/250\n",
            "243/243 - 2s - loss: 0.4170 - accuracy: 0.8400\n",
            "Epoch 6/250\n",
            "243/243 - 2s - loss: 0.3931 - accuracy: 0.8509\n",
            "Epoch 7/250\n",
            "243/243 - 2s - loss: 0.3757 - accuracy: 0.8571\n",
            "Epoch 8/250\n",
            "243/243 - 2s - loss: 0.3647 - accuracy: 0.8617\n",
            "Epoch 9/250\n",
            "243/243 - 2s - loss: 0.3525 - accuracy: 0.8658\n",
            "Epoch 10/250\n",
            "243/243 - 2s - loss: 0.3442 - accuracy: 0.8703\n",
            "Epoch 11/250\n",
            "243/243 - 2s - loss: 0.3402 - accuracy: 0.8714\n",
            "Epoch 12/250\n",
            "243/243 - 2s - loss: 0.3241 - accuracy: 0.8771\n",
            "Epoch 13/250\n",
            "243/243 - 2s - loss: 0.3122 - accuracy: 0.8816\n",
            "Epoch 14/250\n",
            "243/243 - 2s - loss: 0.3069 - accuracy: 0.8841\n",
            "Epoch 15/250\n",
            "243/243 - 2s - loss: 0.3118 - accuracy: 0.8814\n",
            "Epoch 16/250\n",
            "243/243 - 2s - loss: 0.2973 - accuracy: 0.8875\n",
            "Epoch 17/250\n",
            "243/243 - 2s - loss: 0.2879 - accuracy: 0.8903\n",
            "Epoch 18/250\n",
            "243/243 - 2s - loss: 0.2880 - accuracy: 0.8906\n",
            "Epoch 19/250\n",
            "243/243 - 2s - loss: 0.2814 - accuracy: 0.8942\n",
            "Epoch 20/250\n",
            "243/243 - 2s - loss: 0.2759 - accuracy: 0.8958\n",
            "Epoch 21/250\n",
            "243/243 - 2s - loss: 0.2683 - accuracy: 0.8981\n",
            "Epoch 22/250\n",
            "243/243 - 2s - loss: 0.2649 - accuracy: 0.9002\n",
            "Epoch 23/250\n",
            "243/243 - 2s - loss: 0.2640 - accuracy: 0.9009\n",
            "Epoch 24/250\n",
            "243/243 - 2s - loss: 0.2516 - accuracy: 0.9057\n",
            "Epoch 25/250\n",
            "243/243 - 2s - loss: 0.2485 - accuracy: 0.9052\n",
            "Epoch 26/250\n",
            "243/243 - 2s - loss: 0.2487 - accuracy: 0.9072\n",
            "Epoch 27/250\n",
            "243/243 - 2s - loss: 0.2430 - accuracy: 0.9076\n",
            "Epoch 28/250\n",
            "243/243 - 2s - loss: 0.2421 - accuracy: 0.9085\n",
            "Epoch 29/250\n",
            "243/243 - 2s - loss: 0.2407 - accuracy: 0.9091\n",
            "Epoch 30/250\n",
            "243/243 - 2s - loss: 0.2378 - accuracy: 0.9114\n",
            "Epoch 31/250\n",
            "243/243 - 2s - loss: 0.2338 - accuracy: 0.9113\n",
            "Epoch 32/250\n",
            "243/243 - 2s - loss: 0.2305 - accuracy: 0.9133\n",
            "Epoch 33/250\n",
            "243/243 - 2s - loss: 0.2244 - accuracy: 0.9141\n",
            "Epoch 34/250\n",
            "243/243 - 2s - loss: 0.2253 - accuracy: 0.9144\n",
            "Epoch 35/250\n",
            "243/243 - 2s - loss: 0.2218 - accuracy: 0.9146\n",
            "Epoch 36/250\n",
            "243/243 - 2s - loss: 0.2217 - accuracy: 0.9162\n",
            "Epoch 37/250\n",
            "243/243 - 2s - loss: 0.2187 - accuracy: 0.9166\n",
            "Epoch 38/250\n",
            "243/243 - 2s - loss: 0.2163 - accuracy: 0.9183\n",
            "Epoch 39/250\n",
            "243/243 - 2s - loss: 0.2173 - accuracy: 0.9176\n",
            "Epoch 40/250\n",
            "243/243 - 2s - loss: 0.2062 - accuracy: 0.9217\n",
            "Epoch 41/250\n",
            "243/243 - 2s - loss: 0.2131 - accuracy: 0.9180\n",
            "Epoch 42/250\n",
            "243/243 - 2s - loss: 0.2062 - accuracy: 0.9211\n",
            "Epoch 43/250\n",
            "243/243 - 2s - loss: 0.2046 - accuracy: 0.9228\n",
            "Epoch 44/250\n",
            "243/243 - 2s - loss: 0.2003 - accuracy: 0.9238\n",
            "Epoch 45/250\n",
            "243/243 - 2s - loss: 0.2033 - accuracy: 0.9232\n",
            "Epoch 46/250\n",
            "243/243 - 2s - loss: 0.1976 - accuracy: 0.9250\n",
            "Epoch 47/250\n",
            "243/243 - 2s - loss: 0.1947 - accuracy: 0.9260\n",
            "Epoch 48/250\n",
            "243/243 - 2s - loss: 0.1968 - accuracy: 0.9248\n",
            "Epoch 49/250\n",
            "243/243 - 2s - loss: 0.1915 - accuracy: 0.9264\n",
            "Epoch 50/250\n",
            "243/243 - 2s - loss: 0.1893 - accuracy: 0.9289\n",
            "Epoch 51/250\n",
            "243/243 - 2s - loss: 0.1909 - accuracy: 0.9276\n",
            "Epoch 52/250\n",
            "243/243 - 2s - loss: 0.1859 - accuracy: 0.9289\n",
            "Epoch 53/250\n",
            "243/243 - 2s - loss: 0.1818 - accuracy: 0.9314\n",
            "Epoch 54/250\n",
            "243/243 - 2s - loss: 0.1819 - accuracy: 0.9305\n",
            "Epoch 55/250\n",
            "243/243 - 2s - loss: 0.1809 - accuracy: 0.9315\n",
            "Epoch 56/250\n",
            "243/243 - 2s - loss: 0.1844 - accuracy: 0.9296\n",
            "Epoch 57/250\n",
            "243/243 - 2s - loss: 0.1799 - accuracy: 0.9314\n",
            "Epoch 58/250\n",
            "243/243 - 2s - loss: 0.1774 - accuracy: 0.9327\n",
            "Epoch 59/250\n",
            "243/243 - 2s - loss: 0.1789 - accuracy: 0.9317\n",
            "Epoch 60/250\n",
            "243/243 - 2s - loss: 0.1734 - accuracy: 0.9345\n",
            "Epoch 61/250\n",
            "243/243 - 2s - loss: 0.1731 - accuracy: 0.9350\n",
            "Epoch 62/250\n",
            "243/243 - 2s - loss: 0.1740 - accuracy: 0.9338\n",
            "Epoch 63/250\n",
            "243/243 - 2s - loss: 0.1696 - accuracy: 0.9351\n",
            "Epoch 64/250\n",
            "243/243 - 2s - loss: 0.1665 - accuracy: 0.9371\n",
            "Epoch 65/250\n",
            "243/243 - 2s - loss: 0.1689 - accuracy: 0.9349\n",
            "Epoch 66/250\n",
            "243/243 - 2s - loss: 0.1768 - accuracy: 0.9324\n",
            "Epoch 67/250\n",
            "243/243 - 2s - loss: 0.1643 - accuracy: 0.9371\n",
            "Epoch 68/250\n",
            "243/243 - 2s - loss: 0.1613 - accuracy: 0.9390\n",
            "Epoch 69/250\n",
            "243/243 - 2s - loss: 0.1604 - accuracy: 0.9382\n",
            "Epoch 70/250\n",
            "243/243 - 2s - loss: 0.1602 - accuracy: 0.9386\n",
            "Epoch 71/250\n",
            "243/243 - 2s - loss: 0.1612 - accuracy: 0.9391\n",
            "Epoch 72/250\n",
            "243/243 - 2s - loss: 0.1634 - accuracy: 0.9367\n",
            "Epoch 73/250\n",
            "243/243 - 2s - loss: 0.1531 - accuracy: 0.9427\n",
            "Epoch 74/250\n",
            "243/243 - 2s - loss: 0.1517 - accuracy: 0.9420\n",
            "Epoch 75/250\n",
            "243/243 - 2s - loss: 0.1505 - accuracy: 0.9430\n",
            "Epoch 76/250\n",
            "243/243 - 2s - loss: 0.1489 - accuracy: 0.9447\n",
            "Epoch 77/250\n",
            "243/243 - 2s - loss: 0.1504 - accuracy: 0.9423\n",
            "Epoch 78/250\n",
            "243/243 - 2s - loss: 0.1518 - accuracy: 0.9422\n",
            "Epoch 79/250\n",
            "243/243 - 2s - loss: 0.1490 - accuracy: 0.9430\n",
            "Epoch 80/250\n",
            "243/243 - 2s - loss: 0.1486 - accuracy: 0.9427\n",
            "Epoch 81/250\n",
            "243/243 - 2s - loss: 0.1433 - accuracy: 0.9450\n",
            "Epoch 82/250\n",
            "243/243 - 2s - loss: 0.1507 - accuracy: 0.9423\n",
            "Epoch 83/250\n",
            "243/243 - 2s - loss: 0.1474 - accuracy: 0.9436\n",
            "Epoch 84/250\n",
            "243/243 - 2s - loss: 0.1462 - accuracy: 0.9434\n",
            "Epoch 85/250\n",
            "243/243 - 2s - loss: 0.1463 - accuracy: 0.9450\n",
            "Epoch 86/250\n",
            "243/243 - 2s - loss: 0.1367 - accuracy: 0.9478\n",
            "Epoch 87/250\n",
            "243/243 - 2s - loss: 0.1480 - accuracy: 0.9430\n",
            "Epoch 88/250\n",
            "243/243 - 2s - loss: 0.1417 - accuracy: 0.9463\n",
            "Epoch 89/250\n",
            "243/243 - 2s - loss: 0.1372 - accuracy: 0.9487\n",
            "Epoch 90/250\n",
            "243/243 - 2s - loss: 0.1359 - accuracy: 0.9476\n",
            "Epoch 91/250\n",
            "243/243 - 2s - loss: 0.1347 - accuracy: 0.9495\n",
            "Epoch 92/250\n",
            "243/243 - 2s - loss: 0.1348 - accuracy: 0.9479\n",
            "Epoch 93/250\n",
            "243/243 - 2s - loss: 0.1328 - accuracy: 0.9491\n",
            "Epoch 94/250\n",
            "243/243 - 2s - loss: 0.1333 - accuracy: 0.9488\n",
            "Epoch 95/250\n",
            "243/243 - 2s - loss: 0.1264 - accuracy: 0.9515\n",
            "Epoch 96/250\n",
            "243/243 - 2s - loss: 0.1304 - accuracy: 0.9509\n",
            "Epoch 97/250\n",
            "243/243 - 2s - loss: 0.1317 - accuracy: 0.9492\n",
            "Epoch 98/250\n",
            "243/243 - 2s - loss: 0.1349 - accuracy: 0.9478\n",
            "Epoch 99/250\n",
            "243/243 - 2s - loss: 0.1230 - accuracy: 0.9526\n",
            "Epoch 100/250\n",
            "243/243 - 2s - loss: 0.1240 - accuracy: 0.9533\n",
            "Epoch 101/250\n",
            "243/243 - 2s - loss: 0.1196 - accuracy: 0.9549\n",
            "Epoch 102/250\n",
            "243/243 - 2s - loss: 0.1313 - accuracy: 0.9503\n",
            "Epoch 103/250\n",
            "243/243 - 2s - loss: 0.1252 - accuracy: 0.9527\n",
            "Epoch 104/250\n",
            "243/243 - 2s - loss: 0.1212 - accuracy: 0.9540\n",
            "Epoch 105/250\n",
            "243/243 - 2s - loss: 0.1189 - accuracy: 0.9541\n",
            "Epoch 106/250\n",
            "243/243 - 2s - loss: 0.1188 - accuracy: 0.9543\n",
            "Epoch 107/250\n",
            "243/243 - 2s - loss: 0.1236 - accuracy: 0.9526\n",
            "Epoch 108/250\n",
            "243/243 - 2s - loss: 0.1173 - accuracy: 0.9549\n",
            "Epoch 109/250\n",
            "243/243 - 2s - loss: 0.1204 - accuracy: 0.9543\n",
            "Epoch 110/250\n",
            "243/243 - 2s - loss: 0.1108 - accuracy: 0.9582\n",
            "Epoch 111/250\n",
            "243/243 - 2s - loss: 0.1160 - accuracy: 0.9555\n",
            "Epoch 112/250\n",
            "243/243 - 2s - loss: 0.1133 - accuracy: 0.9564\n",
            "Epoch 113/250\n",
            "243/243 - 2s - loss: 0.1170 - accuracy: 0.9556\n",
            "Epoch 114/250\n",
            "243/243 - 2s - loss: 0.1149 - accuracy: 0.9563\n",
            "Epoch 115/250\n",
            "243/243 - 2s - loss: 0.1086 - accuracy: 0.9573\n",
            "Epoch 116/250\n",
            "243/243 - 2s - loss: 0.1157 - accuracy: 0.9565\n",
            "Epoch 117/250\n",
            "243/243 - 2s - loss: 0.1111 - accuracy: 0.9585\n",
            "Epoch 118/250\n",
            "243/243 - 2s - loss: 0.1123 - accuracy: 0.9563\n",
            "Epoch 119/250\n",
            "243/243 - 2s - loss: 0.1040 - accuracy: 0.9602\n",
            "Epoch 120/250\n",
            "243/243 - 2s - loss: 0.1089 - accuracy: 0.9580\n",
            "Epoch 121/250\n",
            "243/243 - 2s - loss: 0.1095 - accuracy: 0.9583\n",
            "Epoch 122/250\n",
            "243/243 - 2s - loss: 0.1019 - accuracy: 0.9610\n",
            "Epoch 123/250\n",
            "243/243 - 2s - loss: 0.1016 - accuracy: 0.9621\n",
            "Epoch 124/250\n",
            "243/243 - 2s - loss: 0.1071 - accuracy: 0.9597\n",
            "Epoch 125/250\n",
            "243/243 - 2s - loss: 0.1053 - accuracy: 0.9594\n",
            "Epoch 126/250\n",
            "243/243 - 2s - loss: 0.1032 - accuracy: 0.9612\n",
            "Epoch 127/250\n",
            "243/243 - 2s - loss: 0.1017 - accuracy: 0.9610\n",
            "Epoch 128/250\n",
            "243/243 - 2s - loss: 0.1089 - accuracy: 0.9577\n",
            "Epoch 129/250\n",
            "243/243 - 2s - loss: 0.0986 - accuracy: 0.9625\n",
            "Epoch 130/250\n",
            "243/243 - 2s - loss: 0.1017 - accuracy: 0.9615\n",
            "Epoch 131/250\n",
            "243/243 - 2s - loss: 0.0980 - accuracy: 0.9630\n",
            "Epoch 132/250\n",
            "243/243 - 2s - loss: 0.0986 - accuracy: 0.9617\n",
            "Epoch 133/250\n",
            "243/243 - 2s - loss: 0.0982 - accuracy: 0.9630\n",
            "Epoch 134/250\n",
            "243/243 - 2s - loss: 0.0900 - accuracy: 0.9661\n",
            "Epoch 135/250\n",
            "243/243 - 2s - loss: 0.0986 - accuracy: 0.9626\n",
            "Epoch 136/250\n",
            "243/243 - 2s - loss: 0.0981 - accuracy: 0.9633\n",
            "Epoch 137/250\n",
            "243/243 - 2s - loss: 0.0927 - accuracy: 0.9652\n",
            "Epoch 138/250\n",
            "243/243 - 2s - loss: 0.0910 - accuracy: 0.9653\n",
            "Epoch 139/250\n",
            "243/243 - 2s - loss: 0.1004 - accuracy: 0.9624\n",
            "Epoch 140/250\n",
            "243/243 - 2s - loss: 0.0960 - accuracy: 0.9637\n",
            "Epoch 141/250\n",
            "243/243 - 2s - loss: 0.0908 - accuracy: 0.9653\n",
            "Epoch 142/250\n",
            "243/243 - 2s - loss: 0.0891 - accuracy: 0.9665\n",
            "Epoch 143/250\n",
            "243/243 - 2s - loss: 0.0874 - accuracy: 0.9657\n",
            "Epoch 144/250\n",
            "243/243 - 2s - loss: 0.0832 - accuracy: 0.9679\n",
            "Epoch 145/250\n",
            "243/243 - 2s - loss: 0.0898 - accuracy: 0.9654\n",
            "Epoch 146/250\n",
            "243/243 - 2s - loss: 0.0812 - accuracy: 0.9694\n",
            "Epoch 147/250\n",
            "243/243 - 2s - loss: 0.0857 - accuracy: 0.9669\n",
            "Epoch 148/250\n",
            "243/243 - 2s - loss: 0.0852 - accuracy: 0.9675\n",
            "Epoch 149/250\n",
            "243/243 - 2s - loss: 0.0891 - accuracy: 0.9655\n",
            "Epoch 150/250\n",
            "243/243 - 2s - loss: 0.0851 - accuracy: 0.9681\n",
            "Epoch 151/250\n",
            "243/243 - 2s - loss: 0.0905 - accuracy: 0.9658\n",
            "Epoch 152/250\n",
            "243/243 - 2s - loss: 0.0821 - accuracy: 0.9685\n",
            "Epoch 153/250\n",
            "243/243 - 2s - loss: 0.0866 - accuracy: 0.9668\n",
            "Epoch 154/250\n",
            "243/243 - 2s - loss: 0.0839 - accuracy: 0.9682\n",
            "Epoch 155/250\n",
            "243/243 - 2s - loss: 0.0813 - accuracy: 0.9692\n",
            "Epoch 156/250\n",
            "243/243 - 2s - loss: 0.0757 - accuracy: 0.9708\n",
            "Epoch 157/250\n",
            "243/243 - 2s - loss: 0.0821 - accuracy: 0.9686\n",
            "Epoch 158/250\n",
            "243/243 - 2s - loss: 0.0836 - accuracy: 0.9682\n",
            "Epoch 159/250\n",
            "243/243 - 2s - loss: 0.0776 - accuracy: 0.9700\n",
            "Epoch 160/250\n",
            "243/243 - 2s - loss: 0.0788 - accuracy: 0.9698\n",
            "Epoch 161/250\n",
            "243/243 - 2s - loss: 0.0772 - accuracy: 0.9711\n",
            "Epoch 162/250\n",
            "243/243 - 2s - loss: 0.0831 - accuracy: 0.9689\n",
            "Epoch 163/250\n",
            "243/243 - 2s - loss: 0.0728 - accuracy: 0.9724\n",
            "Epoch 164/250\n",
            "243/243 - 2s - loss: 0.0811 - accuracy: 0.9686\n",
            "Epoch 165/250\n",
            "243/243 - 2s - loss: 0.0855 - accuracy: 0.9674\n",
            "Epoch 166/250\n",
            "243/243 - 2s - loss: 0.0692 - accuracy: 0.9734\n",
            "Epoch 167/250\n",
            "243/243 - 2s - loss: 0.0770 - accuracy: 0.9705\n",
            "Epoch 168/250\n",
            "243/243 - 2s - loss: 0.0739 - accuracy: 0.9717\n",
            "Epoch 169/250\n",
            "243/243 - 2s - loss: 0.0816 - accuracy: 0.9689\n",
            "Epoch 170/250\n",
            "243/243 - 2s - loss: 0.0774 - accuracy: 0.9709\n",
            "Epoch 171/250\n",
            "243/243 - 2s - loss: 0.0809 - accuracy: 0.9696\n",
            "Epoch 172/250\n",
            "243/243 - 2s - loss: 0.0705 - accuracy: 0.9737\n",
            "Epoch 173/250\n",
            "243/243 - 2s - loss: 0.0664 - accuracy: 0.9748\n",
            "Epoch 174/250\n",
            "243/243 - 2s - loss: 0.0714 - accuracy: 0.9735\n",
            "Epoch 175/250\n",
            "243/243 - 2s - loss: 0.0642 - accuracy: 0.9761\n",
            "Epoch 176/250\n",
            "243/243 - 2s - loss: 0.0690 - accuracy: 0.9741\n",
            "Epoch 177/250\n",
            "243/243 - 2s - loss: 0.0725 - accuracy: 0.9724\n",
            "Epoch 178/250\n",
            "243/243 - 2s - loss: 0.0767 - accuracy: 0.9711\n",
            "Epoch 179/250\n",
            "243/243 - 2s - loss: 0.0761 - accuracy: 0.9714\n",
            "Epoch 180/250\n",
            "243/243 - 2s - loss: 0.0686 - accuracy: 0.9739\n",
            "Epoch 181/250\n",
            "243/243 - 2s - loss: 0.0587 - accuracy: 0.9783\n",
            "Epoch 182/250\n",
            "243/243 - 2s - loss: 0.0708 - accuracy: 0.9731\n",
            "Epoch 183/250\n",
            "243/243 - 2s - loss: 0.0714 - accuracy: 0.9727\n",
            "Epoch 184/250\n",
            "243/243 - 2s - loss: 0.0728 - accuracy: 0.9721\n",
            "Epoch 185/250\n",
            "243/243 - 2s - loss: 0.0738 - accuracy: 0.9719\n",
            "Epoch 186/250\n",
            "243/243 - 2s - loss: 0.0688 - accuracy: 0.9739\n",
            "Epoch 187/250\n",
            "243/243 - 2s - loss: 0.0594 - accuracy: 0.9780\n",
            "Epoch 188/250\n",
            "243/243 - 2s - loss: 0.0671 - accuracy: 0.9749\n",
            "Epoch 189/250\n",
            "243/243 - 2s - loss: 0.0675 - accuracy: 0.9745\n",
            "Epoch 190/250\n",
            "243/243 - 2s - loss: 0.0603 - accuracy: 0.9773\n",
            "Epoch 191/250\n",
            "243/243 - 2s - loss: 0.0624 - accuracy: 0.9768\n",
            "Epoch 192/250\n",
            "243/243 - 2s - loss: 0.0572 - accuracy: 0.9784\n",
            "Epoch 193/250\n",
            "243/243 - 2s - loss: 0.0699 - accuracy: 0.9731\n",
            "Epoch 194/250\n",
            "243/243 - 2s - loss: 0.0594 - accuracy: 0.9780\n",
            "Epoch 195/250\n",
            "243/243 - 2s - loss: 0.0648 - accuracy: 0.9761\n",
            "Epoch 196/250\n",
            "243/243 - 2s - loss: 0.0563 - accuracy: 0.9796\n",
            "Epoch 197/250\n",
            "243/243 - 2s - loss: 0.0596 - accuracy: 0.9778\n",
            "Epoch 198/250\n",
            "243/243 - 2s - loss: 0.0717 - accuracy: 0.9725\n",
            "Epoch 199/250\n",
            "243/243 - 2s - loss: 0.0686 - accuracy: 0.9738\n",
            "Epoch 200/250\n",
            "243/243 - 2s - loss: 0.0582 - accuracy: 0.9788\n",
            "Epoch 201/250\n",
            "243/243 - 2s - loss: 0.0578 - accuracy: 0.9779\n",
            "Epoch 202/250\n",
            "243/243 - 2s - loss: 0.0608 - accuracy: 0.9771\n",
            "Epoch 203/250\n",
            "243/243 - 2s - loss: 0.0586 - accuracy: 0.9774\n",
            "Epoch 204/250\n",
            "243/243 - 2s - loss: 0.0593 - accuracy: 0.9775\n",
            "Epoch 205/250\n",
            "243/243 - 2s - loss: 0.0684 - accuracy: 0.9741\n",
            "Epoch 206/250\n",
            "243/243 - 2s - loss: 0.0466 - accuracy: 0.9830\n",
            "Epoch 207/250\n",
            "243/243 - 2s - loss: 0.0529 - accuracy: 0.9802\n",
            "Epoch 208/250\n",
            "243/243 - 2s - loss: 0.0620 - accuracy: 0.9763\n",
            "Epoch 209/250\n",
            "243/243 - 2s - loss: 0.0625 - accuracy: 0.9769\n",
            "Epoch 210/250\n",
            "243/243 - 2s - loss: 0.0608 - accuracy: 0.9766\n",
            "Epoch 211/250\n",
            "243/243 - 2s - loss: 0.0541 - accuracy: 0.9801\n",
            "Epoch 212/250\n",
            "243/243 - 2s - loss: 0.0612 - accuracy: 0.9775\n",
            "Epoch 213/250\n",
            "243/243 - 2s - loss: 0.0564 - accuracy: 0.9795\n",
            "Epoch 214/250\n",
            "243/243 - 2s - loss: 0.0599 - accuracy: 0.9773\n",
            "Epoch 215/250\n",
            "243/243 - 2s - loss: 0.0608 - accuracy: 0.9776\n",
            "Epoch 216/250\n",
            "243/243 - 2s - loss: 0.0569 - accuracy: 0.9784\n",
            "Epoch 217/250\n",
            "243/243 - 2s - loss: 0.0522 - accuracy: 0.9809\n",
            "Epoch 218/250\n",
            "243/243 - 2s - loss: 0.0527 - accuracy: 0.9796\n",
            "Epoch 219/250\n",
            "243/243 - 2s - loss: 0.0562 - accuracy: 0.9786\n",
            "Epoch 220/250\n",
            "243/243 - 2s - loss: 0.0572 - accuracy: 0.9782\n",
            "Epoch 221/250\n",
            "243/243 - 2s - loss: 0.0573 - accuracy: 0.9788\n",
            "Epoch 222/250\n",
            "243/243 - 2s - loss: 0.0618 - accuracy: 0.9769\n",
            "Epoch 223/250\n",
            "243/243 - 2s - loss: 0.0542 - accuracy: 0.9798\n",
            "Epoch 224/250\n",
            "243/243 - 2s - loss: 0.0618 - accuracy: 0.9780\n",
            "Epoch 225/250\n",
            "243/243 - 2s - loss: 0.0549 - accuracy: 0.9794\n",
            "Epoch 226/250\n",
            "243/243 - 2s - loss: 0.0447 - accuracy: 0.9836\n",
            "Epoch 227/250\n",
            "243/243 - 2s - loss: 0.0523 - accuracy: 0.9803\n",
            "Epoch 228/250\n",
            "243/243 - 2s - loss: 0.0492 - accuracy: 0.9820\n",
            "Epoch 229/250\n",
            "243/243 - 2s - loss: 0.0506 - accuracy: 0.9813\n",
            "Epoch 230/250\n",
            "243/243 - 2s - loss: 0.1068 - accuracy: 0.9638\n",
            "Epoch 231/250\n",
            "243/243 - 2s - loss: 0.0445 - accuracy: 0.9835\n",
            "Epoch 232/250\n",
            "243/243 - 2s - loss: 0.0493 - accuracy: 0.9817\n",
            "Epoch 233/250\n",
            "243/243 - 2s - loss: 0.0454 - accuracy: 0.9830\n",
            "Epoch 234/250\n",
            "243/243 - 2s - loss: 0.0459 - accuracy: 0.9832\n",
            "Epoch 235/250\n",
            "243/243 - 2s - loss: 0.0489 - accuracy: 0.9815\n",
            "Epoch 236/250\n",
            "243/243 - 2s - loss: 0.0474 - accuracy: 0.9826\n",
            "Epoch 237/250\n",
            "243/243 - 2s - loss: 0.0510 - accuracy: 0.9807\n",
            "Epoch 238/250\n",
            "243/243 - 2s - loss: 0.0563 - accuracy: 0.9790\n",
            "Epoch 239/250\n",
            "243/243 - 2s - loss: 0.0503 - accuracy: 0.9813\n",
            "Epoch 240/250\n",
            "243/243 - 2s - loss: 0.0495 - accuracy: 0.9817\n",
            "Epoch 241/250\n",
            "243/243 - 2s - loss: 0.0420 - accuracy: 0.9843\n",
            "Epoch 242/250\n",
            "243/243 - 2s - loss: 0.0529 - accuracy: 0.9802\n",
            "Epoch 243/250\n",
            "243/243 - 2s - loss: 0.0458 - accuracy: 0.9836\n",
            "Epoch 244/250\n",
            "243/243 - 2s - loss: 0.0571 - accuracy: 0.9791\n",
            "Epoch 245/250\n",
            "243/243 - 2s - loss: 0.0439 - accuracy: 0.9844\n",
            "Epoch 246/250\n",
            "243/243 - 2s - loss: 0.0525 - accuracy: 0.9801\n",
            "Epoch 247/250\n",
            "243/243 - 2s - loss: 0.0512 - accuracy: 0.9809\n",
            "Epoch 248/250\n",
            "243/243 - 2s - loss: 0.0491 - accuracy: 0.9814\n",
            "Epoch 249/250\n",
            "243/243 - 2s - loss: 0.0549 - accuracy: 0.9796\n",
            "Epoch 250/250\n",
            "243/243 - 2s - loss: 0.0468 - accuracy: 0.9822\n",
            "Epoch 1/150\n",
            "243/243 - 38s - loss: 0.7267 - accuracy: 0.7401\n",
            "Epoch 2/150\n",
            "243/243 - 20s - loss: 0.4036 - accuracy: 0.8525\n",
            "Epoch 3/150\n",
            "243/243 - 19s - loss: 0.3504 - accuracy: 0.8768\n",
            "Epoch 4/150\n",
            "243/243 - 20s - loss: 0.2663 - accuracy: 0.9028\n",
            "Epoch 5/150\n",
            "243/243 - 19s - loss: 0.3142 - accuracy: 0.8879\n",
            "Epoch 6/150\n",
            "243/243 - 19s - loss: 0.2446 - accuracy: 0.9124\n",
            "Epoch 7/150\n",
            "243/243 - 20s - loss: 0.2594 - accuracy: 0.9110\n",
            "Epoch 8/150\n",
            "243/243 - 19s - loss: 0.1925 - accuracy: 0.9277\n",
            "Epoch 9/150\n",
            "243/243 - 19s - loss: 0.1624 - accuracy: 0.9397\n",
            "Epoch 10/150\n",
            "243/243 - 19s - loss: 0.1475 - accuracy: 0.9451\n",
            "Epoch 11/150\n",
            "243/243 - 20s - loss: 0.1470 - accuracy: 0.9461\n",
            "Epoch 12/150\n",
            "243/243 - 19s - loss: 0.2826 - accuracy: 0.9057\n",
            "Epoch 13/150\n",
            "243/243 - 19s - loss: 0.2302 - accuracy: 0.9144\n",
            "Epoch 14/150\n",
            "243/243 - 19s - loss: 0.1834 - accuracy: 0.9321\n",
            "Epoch 15/150\n",
            "243/243 - 19s - loss: 0.1772 - accuracy: 0.9353\n",
            "Epoch 16/150\n",
            "243/243 - 19s - loss: 0.1491 - accuracy: 0.9439\n",
            "Epoch 17/150\n",
            "243/243 - 19s - loss: 0.1342 - accuracy: 0.9489\n",
            "Epoch 18/150\n",
            "243/243 - 19s - loss: 0.1197 - accuracy: 0.9551\n",
            "Epoch 19/150\n",
            "243/243 - 19s - loss: 0.1224 - accuracy: 0.9544\n",
            "Epoch 20/150\n",
            "243/243 - 19s - loss: 0.1088 - accuracy: 0.9595\n",
            "Epoch 21/150\n",
            "243/243 - 19s - loss: 0.1040 - accuracy: 0.9605\n",
            "Epoch 22/150\n",
            "243/243 - 19s - loss: 0.1093 - accuracy: 0.9593\n",
            "Epoch 23/150\n",
            "243/243 - 19s - loss: 0.1102 - accuracy: 0.9596\n",
            "Epoch 24/150\n",
            "243/243 - 19s - loss: 0.2578 - accuracy: 0.9246\n",
            "Epoch 25/150\n",
            "243/243 - 19s - loss: 0.1626 - accuracy: 0.9405\n",
            "Epoch 26/150\n",
            "243/243 - 19s - loss: 0.1272 - accuracy: 0.9535\n",
            "Epoch 27/150\n",
            "243/243 - 19s - loss: 0.1065 - accuracy: 0.9608\n",
            "Epoch 28/150\n",
            "243/243 - 19s - loss: 0.0973 - accuracy: 0.9641\n",
            "Epoch 29/150\n",
            "243/243 - 19s - loss: 0.0883 - accuracy: 0.9672\n",
            "Epoch 30/150\n",
            "243/243 - 19s - loss: 0.0798 - accuracy: 0.9709\n",
            "Epoch 31/150\n",
            "243/243 - 19s - loss: 0.0756 - accuracy: 0.9723\n",
            "Epoch 32/150\n",
            "243/243 - 19s - loss: 0.1209 - accuracy: 0.9674\n",
            "Epoch 33/150\n",
            "243/243 - 19s - loss: 0.0904 - accuracy: 0.9690\n",
            "Epoch 34/150\n",
            "243/243 - 19s - loss: 0.0656 - accuracy: 0.9764\n",
            "Epoch 35/150\n",
            "243/243 - 19s - loss: 0.0681 - accuracy: 0.9750\n",
            "Epoch 36/150\n",
            "243/243 - 19s - loss: 0.0653 - accuracy: 0.9781\n",
            "Epoch 37/150\n",
            "243/243 - 19s - loss: 0.0626 - accuracy: 0.9775\n",
            "Epoch 38/150\n",
            "243/243 - 19s - loss: 0.0540 - accuracy: 0.9806\n",
            "Epoch 39/150\n",
            "243/243 - 19s - loss: 0.0576 - accuracy: 0.9791\n",
            "Epoch 40/150\n",
            "243/243 - 19s - loss: 0.0542 - accuracy: 0.9804\n",
            "Epoch 41/150\n",
            "243/243 - 19s - loss: 0.0519 - accuracy: 0.9812\n",
            "Epoch 42/150\n",
            "243/243 - 19s - loss: 0.0523 - accuracy: 0.9812\n",
            "Epoch 43/150\n",
            "243/243 - 19s - loss: 0.0461 - accuracy: 0.9842\n",
            "Epoch 44/150\n",
            "243/243 - 19s - loss: 0.0533 - accuracy: 0.9818\n",
            "Epoch 45/150\n",
            "243/243 - 19s - loss: 0.0422 - accuracy: 0.9857\n",
            "Epoch 46/150\n",
            "243/243 - 19s - loss: 0.0505 - accuracy: 0.9816\n",
            "Epoch 47/150\n",
            "243/243 - 19s - loss: 0.0663 - accuracy: 0.9771\n",
            "Epoch 48/150\n",
            "243/243 - 19s - loss: 0.0394 - accuracy: 0.9858\n",
            "Epoch 49/150\n",
            "243/243 - 19s - loss: 0.0435 - accuracy: 0.9849\n",
            "Epoch 50/150\n",
            "243/243 - 19s - loss: 0.0422 - accuracy: 0.9860\n",
            "Epoch 51/150\n",
            "243/243 - 19s - loss: 0.0704 - accuracy: 0.9831\n",
            "Epoch 52/150\n",
            "243/243 - 19s - loss: 0.1426 - accuracy: 0.9545\n",
            "Epoch 53/150\n",
            "243/243 - 19s - loss: 0.0593 - accuracy: 0.9797\n",
            "Epoch 54/150\n",
            "243/243 - 19s - loss: 0.0537 - accuracy: 0.9839\n",
            "Epoch 55/150\n",
            "243/243 - 19s - loss: 0.0316 - accuracy: 0.9887\n",
            "Epoch 56/150\n",
            "243/243 - 19s - loss: 0.0380 - accuracy: 0.9863\n",
            "Epoch 57/150\n",
            "243/243 - 19s - loss: 0.0277 - accuracy: 0.9901\n",
            "Epoch 58/150\n",
            "243/243 - 19s - loss: 0.0258 - accuracy: 0.9918\n",
            "Epoch 59/150\n",
            "243/243 - 19s - loss: 0.0318 - accuracy: 0.9888\n",
            "Epoch 60/150\n",
            "243/243 - 19s - loss: 0.0268 - accuracy: 0.9911\n",
            "Epoch 61/150\n",
            "243/243 - 19s - loss: 0.0258 - accuracy: 0.9908\n",
            "Epoch 62/150\n",
            "243/243 - 19s - loss: 0.0259 - accuracy: 0.9910\n",
            "Epoch 63/150\n",
            "243/243 - 19s - loss: 0.0400 - accuracy: 0.9861\n",
            "Epoch 64/150\n",
            "243/243 - 19s - loss: 0.0264 - accuracy: 0.9909\n",
            "Epoch 65/150\n",
            "243/243 - 19s - loss: 0.0310 - accuracy: 0.9892\n",
            "Epoch 66/150\n",
            "243/243 - 19s - loss: 0.0253 - accuracy: 0.9914\n",
            "Epoch 67/150\n",
            "243/243 - 19s - loss: 0.0246 - accuracy: 0.9918\n",
            "Epoch 68/150\n",
            "243/243 - 19s - loss: 0.0234 - accuracy: 0.9920\n",
            "Epoch 69/150\n",
            "243/243 - 19s - loss: 0.0225 - accuracy: 0.9921\n",
            "Epoch 70/150\n",
            "243/243 - 19s - loss: 0.0254 - accuracy: 0.9912\n",
            "Epoch 71/150\n",
            "243/243 - 19s - loss: 0.0249 - accuracy: 0.9915\n",
            "Epoch 72/150\n",
            "243/243 - 19s - loss: 0.0296 - accuracy: 0.9902\n",
            "Epoch 73/150\n",
            "243/243 - 19s - loss: 0.0234 - accuracy: 0.9922\n",
            "Epoch 74/150\n",
            "243/243 - 19s - loss: 0.0196 - accuracy: 0.9930\n",
            "Epoch 75/150\n",
            "243/243 - 19s - loss: 0.0287 - accuracy: 0.9903\n",
            "Epoch 76/150\n",
            "243/243 - 19s - loss: 0.0227 - accuracy: 0.9921\n",
            "Epoch 77/150\n",
            "243/243 - 19s - loss: 0.0208 - accuracy: 0.9927\n",
            "Epoch 78/150\n",
            "243/243 - 19s - loss: 0.0239 - accuracy: 0.9920\n",
            "Epoch 79/150\n",
            "243/243 - 19s - loss: 0.0167 - accuracy: 0.9944\n",
            "Epoch 80/150\n",
            "243/243 - 19s - loss: 0.0261 - accuracy: 0.9915\n",
            "Epoch 81/150\n",
            "243/243 - 19s - loss: 0.0171 - accuracy: 0.9943\n",
            "Epoch 82/150\n",
            "243/243 - 19s - loss: 0.0176 - accuracy: 0.9943\n",
            "Epoch 83/150\n",
            "243/243 - 19s - loss: 0.3594 - accuracy: 0.9240\n",
            "Epoch 84/150\n",
            "243/243 - 19s - loss: 0.2647 - accuracy: 0.9107\n",
            "Epoch 85/150\n",
            "243/243 - 19s - loss: 0.2021 - accuracy: 0.9365\n",
            "Epoch 86/150\n",
            "243/243 - 19s - loss: 0.1633 - accuracy: 0.9474\n",
            "Epoch 87/150\n",
            "243/243 - 19s - loss: 0.1305 - accuracy: 0.9573\n",
            "Epoch 88/150\n",
            "243/243 - 19s - loss: 0.0943 - accuracy: 0.9667\n",
            "Epoch 89/150\n",
            "243/243 - 19s - loss: 0.0817 - accuracy: 0.9726\n",
            "Epoch 90/150\n",
            "243/243 - 19s - loss: 0.0703 - accuracy: 0.9763\n",
            "Epoch 91/150\n",
            "243/243 - 19s - loss: 0.0786 - accuracy: 0.9750\n",
            "Epoch 92/150\n",
            "243/243 - 19s - loss: 0.0586 - accuracy: 0.9812\n",
            "Epoch 93/150\n",
            "243/243 - 19s - loss: 0.0445 - accuracy: 0.9852\n",
            "Epoch 94/150\n",
            "243/243 - 19s - loss: 0.0361 - accuracy: 0.9886\n",
            "Epoch 95/150\n",
            "243/243 - 19s - loss: 0.0347 - accuracy: 0.9888\n",
            "Epoch 96/150\n",
            "243/243 - 19s - loss: 0.0345 - accuracy: 0.9898\n",
            "Epoch 97/150\n",
            "243/243 - 19s - loss: 0.0269 - accuracy: 0.9917\n",
            "Epoch 98/150\n",
            "243/243 - 19s - loss: 0.0314 - accuracy: 0.9910\n",
            "Epoch 99/150\n",
            "243/243 - 19s - loss: 0.0277 - accuracy: 0.9902\n",
            "Epoch 100/150\n",
            "243/243 - 19s - loss: 0.0281 - accuracy: 0.9911\n",
            "Epoch 101/150\n",
            "243/243 - 19s - loss: 0.1771 - accuracy: 0.9610\n",
            "Epoch 102/150\n",
            "243/243 - 19s - loss: 0.0648 - accuracy: 0.9808\n",
            "Epoch 103/150\n",
            "243/243 - 19s - loss: 0.0643 - accuracy: 0.9801\n",
            "Epoch 104/150\n",
            "243/243 - 19s - loss: 0.0722 - accuracy: 0.9755\n",
            "Epoch 105/150\n",
            "243/243 - 19s - loss: 0.0326 - accuracy: 0.9894\n",
            "Epoch 106/150\n",
            "243/243 - 19s - loss: 0.0343 - accuracy: 0.9881\n",
            "Epoch 107/150\n",
            "243/243 - 19s - loss: 0.0250 - accuracy: 0.9915\n",
            "Epoch 108/150\n",
            "243/243 - 19s - loss: 0.0196 - accuracy: 0.9945\n",
            "Epoch 109/150\n",
            "243/243 - 19s - loss: 0.0375 - accuracy: 0.9879\n",
            "Epoch 110/150\n",
            "243/243 - 19s - loss: 0.0266 - accuracy: 0.9910\n",
            "Epoch 111/150\n",
            "243/243 - 19s - loss: 0.0191 - accuracy: 0.9934\n",
            "Epoch 112/150\n",
            "243/243 - 19s - loss: 0.0131 - accuracy: 0.9954\n",
            "Epoch 113/150\n",
            "243/243 - 19s - loss: 0.0157 - accuracy: 0.9945\n",
            "Epoch 114/150\n",
            "243/243 - 19s - loss: 0.0182 - accuracy: 0.9935\n",
            "Epoch 115/150\n",
            "243/243 - 19s - loss: 0.0148 - accuracy: 0.9951\n",
            "Epoch 116/150\n",
            "243/243 - 19s - loss: 0.0183 - accuracy: 0.9940\n",
            "Epoch 117/150\n",
            "243/243 - 19s - loss: 0.0150 - accuracy: 0.9949\n",
            "Epoch 118/150\n",
            "243/243 - 19s - loss: 0.0157 - accuracy: 0.9941\n",
            "Epoch 119/150\n",
            "243/243 - 19s - loss: 0.0185 - accuracy: 0.9937\n",
            "Epoch 120/150\n",
            "243/243 - 19s - loss: 0.0456 - accuracy: 0.9857\n",
            "Epoch 121/150\n",
            "243/243 - 19s - loss: 0.0143 - accuracy: 0.9951\n",
            "Epoch 122/150\n",
            "243/243 - 19s - loss: 0.0157 - accuracy: 0.9944\n",
            "Epoch 123/150\n",
            "243/243 - 19s - loss: 0.0167 - accuracy: 0.9946\n",
            "Epoch 124/150\n",
            "243/243 - 19s - loss: 0.0192 - accuracy: 0.9941\n",
            "Epoch 125/150\n",
            "243/243 - 19s - loss: 0.0210 - accuracy: 0.9931\n",
            "Epoch 126/150\n",
            "243/243 - 19s - loss: 0.0176 - accuracy: 0.9944\n",
            "Epoch 127/150\n",
            "243/243 - 19s - loss: 0.0349 - accuracy: 0.9912\n",
            "Epoch 128/150\n",
            "243/243 - 19s - loss: 0.2468 - accuracy: 0.9309\n",
            "Epoch 129/150\n",
            "243/243 - 19s - loss: 0.1067 - accuracy: 0.9632\n",
            "Epoch 130/150\n",
            "243/243 - 19s - loss: 0.0784 - accuracy: 0.9739\n",
            "Epoch 131/150\n",
            "243/243 - 19s - loss: 0.0667 - accuracy: 0.9800\n",
            "Epoch 132/150\n",
            "243/243 - 19s - loss: 0.1093 - accuracy: 0.9690\n",
            "Epoch 133/150\n",
            "243/243 - 19s - loss: 0.0544 - accuracy: 0.9824\n",
            "Epoch 134/150\n",
            "243/243 - 19s - loss: 0.0256 - accuracy: 0.9913\n",
            "Epoch 135/150\n",
            "243/243 - 19s - loss: 0.0186 - accuracy: 0.9938\n",
            "Epoch 136/150\n",
            "243/243 - 19s - loss: 0.0161 - accuracy: 0.9944\n",
            "Epoch 137/150\n",
            "243/243 - 19s - loss: 0.0193 - accuracy: 0.9943\n",
            "Epoch 138/150\n",
            "243/243 - 19s - loss: 0.0213 - accuracy: 0.9941\n",
            "Epoch 139/150\n",
            "243/243 - 19s - loss: 0.0194 - accuracy: 0.9951\n",
            "Epoch 140/150\n",
            "243/243 - 19s - loss: 0.0130 - accuracy: 0.9958\n",
            "Epoch 141/150\n",
            "243/243 - 19s - loss: 0.0135 - accuracy: 0.9954\n",
            "Epoch 142/150\n",
            "243/243 - 19s - loss: 0.0192 - accuracy: 0.9938\n",
            "Epoch 143/150\n",
            "243/243 - 19s - loss: 0.0078 - accuracy: 0.9974\n",
            "Epoch 144/150\n",
            "243/243 - 19s - loss: 0.0091 - accuracy: 0.9972\n",
            "Epoch 145/150\n",
            "243/243 - 19s - loss: 0.0189 - accuracy: 0.9938\n",
            "Epoch 146/150\n",
            "243/243 - 19s - loss: 0.0109 - accuracy: 0.9961\n",
            "Epoch 147/150\n",
            "243/243 - 19s - loss: 0.0108 - accuracy: 0.9964\n",
            "Epoch 148/150\n",
            "243/243 - 19s - loss: 0.0100 - accuracy: 0.9968\n",
            "Epoch 149/150\n",
            "243/243 - 19s - loss: 0.0158 - accuracy: 0.9950\n",
            "Epoch 150/150\n",
            "243/243 - 19s - loss: 0.0170 - accuracy: 0.9941\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-7b49ea3ba1da>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     84\u001b[0m                         confidence_factor_array_1, confidence_factor_array_2, confidence_factor_array_3)\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m \u001b[0mY_Test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;31m# Uncomment for Test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'y_test' is not defined"
          ]
        }
      ]
    }
  ]
}