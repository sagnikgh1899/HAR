{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Test ResNet.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "g9PnxXnYSJAl"
      },
      "source": [
        "!nvidia-smi -L"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aRUgspZNSL54"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EPFnmxMwSCjV"
      },
      "source": [
        "# Import necessary Libraries\n",
        "import numpy as np\n",
        "import os\n",
        "import scipy.stats as st\n",
        "import math\n",
        "from sklearn import preprocessing\n",
        "from sklearn import metrics\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics.classification import accuracy_score, recall_score, f1_score\n",
        "from math import exp\n",
        "from math import log\n",
        "import tensorflow as tf\n",
        "\n",
        "import keras\n",
        "from keras import layers\n",
        "# from keras.utils import to_categorical\n",
        "from keras.models import Model, load_model\n",
        "from keras.initializers import glorot_uniform\n",
        "from keras.layers import Input, Dropout, Add, Dense \n",
        "from keras.layers import MaxPooling1D, Reshape, Activation\n",
        "from keras.layers import BatchNormalization, Flatten, Conv1D\n",
        "\n",
        "\n",
        "def DataPreparation_DNN(data_input_file):\n",
        "  data = np.load(data_input_file, allow_pickle=True)\n",
        "  X = data['X']\n",
        "  X = X[:, 0, :, :]\n",
        "  \n",
        "  Y = data['y']\n",
        "  n_class = Y.shape[1]\n",
        "  folds = data['folds']\n",
        "  # Y = np.argmax(Y, axis=1)\n",
        " \n",
        "  return X,Y,folds,n_class\n",
        "\n",
        "\n",
        "# Build ResNet Model\n",
        "def identity_block(input, kernel_size, filters, stage, block):\n",
        "  # Variables\n",
        "  filters1, filters2, filters3 = filters\n",
        "  conv_name_base = 'res' + str(stage) + block + '_branch'\n",
        "  bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
        "  # Create layers\n",
        "  output = keras.layers.Conv1D(filters1, 1, kernel_initializer='he_normal', name=conv_name_base + '2a')(input)\n",
        "  output = keras.layers.BatchNormalization(name=bn_name_base + '2a')(output)\n",
        "  output = keras.layers.Activation('relu')(output)\n",
        "  output = keras.layers.Conv1D(filters2, kernel_size, padding='same', kernel_initializer='he_normal', name=conv_name_base + '2b')(output)\n",
        "  output = keras.layers.BatchNormalization(name=bn_name_base + '2b')(output)\n",
        "  output = keras.layers.Activation('relu')(output)\n",
        "  output = keras.layers.Conv1D(filters3, 1, kernel_initializer='he_normal', name=conv_name_base + '2c')(output)\n",
        "  output = keras.layers.BatchNormalization(name=bn_name_base + '2c')(output)\n",
        "  output = keras.layers.add([output, input])\n",
        "  output = keras.layers.Activation('relu')(output)\n",
        "  # Return a block\n",
        "  return output\n",
        "\n",
        "\n",
        "def conv_block(input, kernel_size, filters, stage, block, strides=2):\n",
        "  # Variables\n",
        "  filters1, filters2, filters3 = filters\n",
        "  conv_name_base = 'res' + str(stage) + block + '_branch'\n",
        "  bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
        "  # Create block layers\n",
        "  output = keras.layers.Conv1D(filters1, 1, strides=strides, kernel_initializer='he_normal', name=conv_name_base + '2a')(input)\n",
        "  output = keras.layers.BatchNormalization(name=bn_name_base + '2a')(output)\n",
        "  output = keras.layers.Activation('relu')(output)\n",
        "  output = keras.layers.Conv1D(filters2, kernel_size, padding='same', kernel_initializer='he_normal', name=conv_name_base + '2b')(output)\n",
        "  output = keras.layers.BatchNormalization(name=bn_name_base + '2b')(output)\n",
        "  output = keras.layers.Activation('relu')(output)\n",
        "  output = keras.layers.Conv1D(filters3, 1, kernel_initializer='he_normal', name=conv_name_base + '2c')(output)\n",
        "  output = keras.layers.BatchNormalization(name=bn_name_base + '2c')(output)\n",
        "  shortcut = keras.layers.Conv1D(filters3, 1, strides=strides, kernel_initializer='he_normal', name=conv_name_base + '1')(input)\n",
        "  shortcut = keras.layers.BatchNormalization(name=bn_name_base + '1')(shortcut)\n",
        "  output = keras.layers.add([output, shortcut])\n",
        "  output = keras.layers.Activation('relu')(output)\n",
        "  # Return a block\n",
        "  return output\n",
        "\n",
        "\n",
        "\n",
        "def build_model_ResNet(row, col, num_classes):\n",
        "  input_shape = (row,col)\n",
        "  # Create an input layer \n",
        "  input = keras.layers.Input(shape=input_shape)\n",
        "  # Create output layers\n",
        "  # output = keras.layers.ZeroPadding2D(padding=2, name='padding_conv1')(input)\n",
        "  output = keras.layers.Conv1D(64, 7, strides=2, use_bias=False, name='conv1')(input)\n",
        "  output = keras.layers.BatchNormalization(name='bn_conv1')(output)\n",
        "  output = keras.layers.Activation('relu', name='conv1_relu')(output)\n",
        "  output = keras.layers.MaxPooling1D(3, strides=2, padding='same', name='pool1')(output)\n",
        "  output = conv_block(output, 3, [64, 64, 256], stage=2, block='a', strides=1)\n",
        "  output = identity_block(output, 3, [64, 64, 256], stage=2, block='b')\n",
        "  output = identity_block(output, 3, [64, 64, 256], stage=2, block='c')\n",
        "  output = conv_block(output, 3, [128, 128, 512], stage=3, block='a')\n",
        "  output = identity_block(output, 3, [128, 128, 512], stage=3, block='b')\n",
        "  output = identity_block(output, 3, [128, 128, 512], stage=3, block='c')\n",
        "  output = identity_block(output, 3, [128, 128, 512], stage=3, block='d')\n",
        "  output = conv_block(output, 3, [256, 256, 1024], stage=4, block='a')\n",
        "  output = identity_block(output, 3, [256, 256, 1024], stage=4, block='b')\n",
        "  output = identity_block(output, 3, [256, 256, 1024], stage=4, block='c')\n",
        "  output = identity_block(output, 3, [256, 256, 1024], stage=4, block='d')\n",
        "  output = identity_block(output, 3, [256, 256, 1024], stage=4, block='e')\n",
        "  output = identity_block(output, 3, [256, 256, 1024], stage=4, block='f')\n",
        "  output = conv_block(output, 3, [512, 512, 2048], stage=5, block='a')\n",
        "  output = identity_block(output, 3, [512, 512, 2048], stage=5, block='b')\n",
        "  output = identity_block(output, 3, [512, 512, 2048], stage=5, block='c')\n",
        "  output = keras.layers.GlobalAveragePooling1D(name='pool5')(output)\n",
        "  output = keras.layers.Dense(num_classes, activation='softmax', name='fc1000')(output)\n",
        "  # Create a model from input layer and output layers\n",
        "  model = keras.models.Model(inputs=input, outputs=output)\n",
        "  # # Print model\n",
        "  # print()\n",
        "  # print(model.summary(), '\\n')\n",
        "  # Compile the model\n",
        "  # Return a model\n",
        "  return model\n",
        "\n",
        "\n",
        "batch_size = 128\n",
        "epochs = 100\n",
        "learning_rate = 0.001\n",
        "\n",
        "\n",
        "def Train_ResNet(X, y, folds):\n",
        "  avg_acc = []\n",
        "  avg_recall = []\n",
        "  avg_f1 = []\n",
        "\n",
        "  n_class = y.shape[1]  \n",
        "  _,img_rows, img_cols = X.shape\n",
        "  X=X.reshape(X.shape[0],img_rows,img_cols,1)\n",
        "  _,img_rows, img_cols,_ = X.shape\n",
        "    \n",
        "  for i in range(3, len(folds)):\n",
        "    train_idx = folds[i][0]\n",
        "    test_idx = folds[i][1]\n",
        "    X_train = X[train_idx]\n",
        "    y_train = y[train_idx]\n",
        "    X_test = X[test_idx]\n",
        "    y_test = y[test_idx]\n",
        "\n",
        "    model=build_model_ResNet(img_rows,img_cols,n_class)\n",
        "    \n",
        "    model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='ADAM')\n",
        "    model.fit(X_train, y_train, batch_size=192, epochs=150,verbose=2)\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    y_pred = np.argmax(y_pred, axis=1)\n",
        "    y_true = np.argmax(y[test_idx], axis=1)\n",
        "    acc_fold = accuracy_score(y_true, y_pred)\n",
        "    avg_acc.append(acc_fold)\n",
        "    recall_fold = recall_score(y_true, y_pred, average='macro')\n",
        "    avg_recall.append(recall_fold)\n",
        "    f1_fold = f1_score(y_true, y_pred, average='macro')\n",
        "    avg_f1.append(f1_fold)\n",
        "    print('Accuracy[{:.4f}] Recall[{:.4f}] F1[{:.4f}] at fold[{}]'.format(acc_fold, recall_fold, f1_fold ,i+1))\n",
        "    print('________________________________________________________________')\n",
        "        \n",
        "  print('Overall Accuracy[{:.4f}] Overall Recall[{:.4f}] Overall F1[{:.4f}]'.format(np.mean(avg_acc), np.mean(avg_recall), np.mean(avg_f1)))\n",
        "  print('________________________________________________________________')\n",
        "\n",
        "  \n",
        "\n",
        "if __name__ == \"__main__\":  \n",
        "  X,y,folds,n_class = DataPreparation_DNN('/content/drive/MyDrive/SNOW/USCHAD.npz')\n",
        "\n",
        "  Train_ResNet(X, y, folds)\n",
        "\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MKGxcfC6SjAa"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
