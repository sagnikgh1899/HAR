{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HaChoi.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "hGaF5g5kBEdv"
      },
      "source": [
        "!pip install tensorflow==1.15\n",
        "!pip install numpy==1.16.1\n",
        "!pip install keras==2.1.2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hK6XsVh5A_Xz"
      },
      "source": [
        "##Libraries\n",
        "import sys\n",
        "import numpy as np\n",
        "import random\n",
        "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
        "from sklearn.metrics.classification import accuracy_score, recall_score, f1_score\n",
        "import scipy.stats as st\n",
        "\n",
        "from tensorflow import keras\n",
        "from keras.layers import Input, Dense, Dropout, Conv2D, Flatten, MaxPooling2D, Activation, concatenate, merge\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, Callback\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.python.keras import backend as K\n",
        "K.set_image_data_format('channels_first')\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tFKz7tRoBEgR"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dJtu85r6BEjH"
      },
      "source": [
        "def custom_model(X, idx_modalities, n_classes):\n",
        "    img_cols1 = idx_modalities[0]\n",
        "    img_cols2 = idx_modalities[1] - idx_modalities[0]\n",
        "    img_cols3 = idx_modalities[2] - idx_modalities[1]\n",
        "    img_cols4 = X.shape[3] - idx_modalities[2]\n",
        "\n",
        "    _, _, img_rows, img_cols = X.shape\n",
        "    inp_modality1 = Input((1, img_rows, img_cols1))\n",
        "    inp_modality2 = Input((1, img_rows, img_cols2))\n",
        "    inp_modality3 = Input((1, img_rows, img_cols3))\n",
        "    inp_modality4 = Input((1, img_rows, img_cols4))\n",
        "\n",
        "    H1 = Conv2D(filters=5, kernel_size=(5, 5))(inp_modality1)\n",
        "    H1 = Activation('relu')(H1)\n",
        "    H1 = MaxPooling2D(pool_size=(4, 4))(H1)\n",
        "\n",
        "    H2 = Conv2D(filters=5, kernel_size=(5, 5))(inp_modality2)\n",
        "    H2 = Activation('relu')(H2)\n",
        "    H2 = MaxPooling2D(pool_size=(4, 4))(H2)\n",
        "\n",
        "    H3 = Conv2D(filters=5, kernel_size=(5, 5))(inp_modality3)\n",
        "    H3 = Activation('relu')(H3)\n",
        "    H3 = MaxPooling2D(pool_size=(4, 4))(H3)\n",
        "\n",
        "    # H4 = Conv2D(filters=5, kernel_size=(5, 3))(inp_modality4)#For PAMAP\n",
        "    H4 = Conv2D(filters=5, kernel_size=(5, 2))(inp_modality4)  # For MEHEALTH\n",
        "    H4 = Activation('relu')(H4)\n",
        "    H4 = MaxPooling2D(pool_size=(4, 1))(H4)\n",
        "\n",
        "    shape_1 = int(H2.shape[1].value)\n",
        "    shape_2 = int(H2.shape[2].value)\n",
        "    shape_3 = int(H2.shape[3].value)\n",
        "    inp_zeros = Input((shape_1, shape_2, shape_3))  # Here is the features map shape\n",
        "\n",
        "    H = concatenate([H1, inp_zeros, H2, inp_zeros, H3, inp_zeros, H4], axis=3)\n",
        "\n",
        "    H = Conv2D(filters=10, kernel_size=(5, 5))(H)\n",
        "    H = Activation('relu')(H)\n",
        "    H = MaxPooling2D(pool_size=(2, 2))(H)\n",
        "\n",
        "    H = Flatten()(H)\n",
        "    H = Dense(120)(H)\n",
        "    H = Activation('relu')(H)\n",
        "\n",
        "    H = Dense(n_classes)(H)\n",
        "    H = Activation('softmax')(H)\n",
        "\n",
        "    model = Model([inp_modality1, inp_modality2, inp_modality3, inp_modality4, inp_zeros], H)\n",
        "\n",
        "    return model, (shape_1, shape_2, shape_3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5rU0pr9IBEl9"
      },
      "source": [
        "def zero_padding_MHEALTH(X):\n",
        "    # Groups the heterogenous sensors for MHEALTH\n",
        "    idx_modalities = []\n",
        "    idx_acc = [0, 1, 2, 5, 6, 7, 14, 15, 16]\n",
        "    idx_gyro = [8, 9, 10, 17, 18, 19]\n",
        "    idx_mag = [11, 12, 13, 20, 21, 22]\n",
        "    idx_ele = [3, 4]\n",
        "    X_acc = X[:, :, :, idx_acc]\n",
        "    X_gyro = X[:, :, :, idx_gyro]\n",
        "    X_mag = X[:, :, :, idx_mag]\n",
        "    X_ele = X[:, :, :, idx_ele]\n",
        "    X_zeros = np.zeros((X.shape[0], X.shape[1], X.shape[2], 2))  # Vertical Kernel-1 = 2\n",
        "\n",
        "    X = X_acc\n",
        "    X = np.concatenate((X, X_zeros), axis=3)\n",
        "    idx_modalities.append(X.shape[3])\n",
        "\n",
        "    X = np.concatenate((X, X_gyro), axis=3)\n",
        "    X = np.concatenate((X, X_zeros),axis=3)\n",
        "    idx_modalities.append(X.shape[3])\n",
        "\n",
        "    X = np.concatenate((X, X_mag),axis=3)\n",
        "    X = np.concatenate((X, X_zeros),axis=3)\n",
        "    idx_modalities.append(X.shape[3])\n",
        "    X = np.concatenate((X, X_ele),axis=3)\n",
        "\n",
        "    return X, idx_modalities"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bC4ltJLxBEpL"
      },
      "source": [
        "def split_X(X, idx_modalities, zeros):\n",
        "    X_tmp = []\n",
        "    X_tmp.append(X[:, :, :, 0:idx_modalities[0]])\n",
        "    X_tmp.append(X[:, :, :, idx_modalities[0]:idx_modalities[1]])\n",
        "    X_tmp.append(X[:, :, :, idx_modalities[1]:idx_modalities[2]])\n",
        "    X_tmp.append(X[:, :, :, idx_modalities[2]:X.shape[3]])\n",
        "    X_tmp.append(zeros)\n",
        "    return X_tmp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5zjoZK1vBErV"
      },
      "source": [
        "def DataPreparation(data_input_file):\n",
        "  np.random.seed(12227)\n",
        "\n",
        "  tmp = np.load(data_input_file)\n",
        "  X = tmp['X']\n",
        "  y = tmp['y']\n",
        "  folds = tmp['folds']\n",
        "\n",
        "  n_class = y.shape[1]\n",
        "\n",
        "  X, idx_modalities = zero_padding_MHEALTH(X)\n",
        "\n",
        "  _, _, img_rows, img_cols = X.shape\n",
        "  return X, y, folds, idx_modalities,n_class"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hqic8-4nBEuJ"
      },
      "source": [
        "def TrainAndReportAccuracies(X,y,folds,idx_modalities,n_class):\n",
        "  avg_acc = []\n",
        "  avg_recall = []\n",
        "  avg_f1 = []\n",
        "  for i in range(0, len(folds)):\n",
        "      train_idx = folds[i][0]\n",
        "      test_idx = folds[i][1]\n",
        "\n",
        "      X_train = X[train_idx]\n",
        "      X_test = X[test_idx]\n",
        "\n",
        "      model, inp_zeros = custom_model(X, idx_modalities, n_classes=n_class)\n",
        "\n",
        "      zeros_mat = np.zeros((X_train.shape[0], inp_zeros[0], inp_zeros[1], inp_zeros[2]))\n",
        "      model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='Adadelta')\n",
        "\n",
        "      X_train = split_X(X_train, idx_modalities, zeros_mat)\n",
        "      print(\"Start Training\")\n",
        "      model.fit(X_train, y[train_idx], batch_size=100, epochs=60,\n",
        "                verbose=1, callbacks=[custom_stopping(value=0.2, verbose=1)], validation_data=(X_train, y[train_idx]))\n",
        "\n",
        "      X_test = split_X(X_test, idx_modalities, zeros_mat)\n",
        "\n",
        "      y_pred = model.predict(X_test)\n",
        "      y_pred = np.argmax(y_pred, axis=1)\n",
        "\n",
        "      y_true = np.argmax(y[test_idx], axis=1)\n",
        "\n",
        "      acc_fold = accuracy_score(y_true, y_pred)\n",
        "      avg_acc.append(acc_fold)\n",
        "\n",
        "      recall_fold = recall_score(y_true, y_pred, average='macro')\n",
        "      avg_recall.append(recall_fold)\n",
        "\n",
        "      f1_fold = f1_score(y_true, y_pred, average='macro')\n",
        "      avg_f1.append(f1_fold)\n",
        "\n",
        "      print('Accuracy[{:.4f}] Recall[{:.4f}] F1[{:.4f}] at fold[{}]'.format(acc_fold, recall_fold, f1_fold, i))\n",
        "      print('______________________________________________________')\n",
        "      del model\n",
        "  ic_acc = st.t.interval(0.9, len(avg_acc) - 1, loc=np.mean(avg_acc), scale=st.sem(avg_acc))\n",
        "  ic_recall = st.t.interval(0.9, len(avg_recall) - 1, loc=np.mean(avg_recall), scale=st.sem(avg_recall))\n",
        "  ic_f1 = st.t.interval(0.9, len(avg_f1) - 1, loc=np.mean(avg_f1), scale=st.sem(avg_f1))\n",
        "  print('Mean Accuracy[{:.4f}] IC [{:.4f}, {:.4f}]'.format(np.mean(avg_acc), ic_acc[0], ic_acc[1]))\n",
        "  print('Mean Recall[{:.4f}] IC [{:.4f}, {:.4f}]'.format(np.mean(avg_recall), ic_recall[0], ic_recall[1]))\n",
        "  print('Mean F1[{:.4f}] IC [{:.4f}, {:.4f}]'.format(np.mean(avg_f1), ic_f1[0], ic_f1[1]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ctEUz7_CBEw0"
      },
      "source": [
        "def Run(data_input_file):\n",
        "  X, y, folds, idx_modalities,n_class= DataPreparation(data_input_file)\n",
        "  TrainAndReportAccuracies(X,y,folds,idx_modalities,n_class)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yu7C8AauBEzv"
      },
      "source": [
        "def WisdomDataPreparation(data_input_file):\n",
        "    np.random.seed(12227)\n",
        "\n",
        "    tmp = np.load(data_input_file)\n",
        "    X = tmp['X']\n",
        "    y = tmp['y']\n",
        "    folds = tmp['folds']\n",
        "\n",
        "    n_class = y.shape[1]\n",
        "   \n",
        "    X=np.pad(X, ((0,0),(0,0), (150,0), (26, 0)), 'constant')\n",
        "    \n",
        "    train_idx = folds[0][0]\n",
        "    test_idx = folds[0][1]\n",
        "\n",
        "    X_train = X[train_idx]\n",
        "    X_test = X[test_idx]\n",
        "    \n",
        "    idx_modalities=[11,19,27]\n",
        "    return X,y,folds,idx_modalities,n_class"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ge1xi6kwBE2I"
      },
      "source": [
        "def RunWisdom(data_input_file):\n",
        "  X,y,folds,idx_modalities,n_class=WisdomDataPreparation(data_input_file)\n",
        "  TrainAndReportAccuracies(X,y,folds,idx_modalities,n_class)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UHpLKAwkBE5D"
      },
      "source": [
        "def WHARFDataPreparation(data_input_file):\n",
        "    np.random.seed(12227)\n",
        "    tmp = np.load(data_input_file)\n",
        "    X = tmp['X']\n",
        "    y = tmp['y']\n",
        "    folds = tmp['folds']\n",
        "    X=np.pad(X, ((0,0),(0,0),(90,0), (26, 0)), 'constant')\n",
        "    n_class = y.shape[1]\n",
        "   \n",
        "    train_idx = folds[0][0]\n",
        "    test_idx = folds[0][1]\n",
        "\n",
        "    X_train = X[train_idx]\n",
        "    X_test = X[test_idx]\n",
        "  \n",
        "\n",
        "    idx_modalities=[11,19,27]\n",
        "    return X,y,folds,idx_modalities,n_class"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9OLfXmmPBE72"
      },
      "source": [
        "def RunWHARF(data_input_file):\n",
        "  # Batch size 100\n",
        "  X,y,folds,idx_modalities,n_class=WHARFDataPreparation(data_input_file)\n",
        "  TrainAndReportAccuracies(X,y,folds,idx_modalities,n_class)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uA4MrhK5BE-e"
      },
      "source": [
        "def MHAD2_1sDataPreparation(data_input_file):\n",
        "    np.random.seed(12227)\n",
        "    tmp = np.load(data_input_file)\n",
        "    X = tmp['X']\n",
        "    y = tmp['y']\n",
        "    folds = tmp['folds']\n",
        "    X=np.pad(X, ((0,0),(0,0),(200,0), (23, 0)), 'constant')\n",
        "    n_class = y.shape[1]\n",
        "    \n",
        "\n",
        "    train_idx = folds[0][0]\n",
        "    test_idx = folds[0][1]\n",
        "\n",
        "    X_train = X[train_idx]\n",
        "    X_test = X[test_idx]\n",
        "    \n",
        "\n",
        "    idx_modalities=[11,19,27]\n",
        "    return X,y,folds,idx_modalities,n_class"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m0A-MX4wBFBV"
      },
      "source": [
        "def RunMHAD2_1s(data_input_file):\n",
        "  # Batch size 100\n",
        "  X,y,folds,idx_modalities,n_class=MHAD2_1sDataPreparation(data_input_file)\n",
        "  TrainAndReportAccuracies(X,y,folds,idx_modalities,n_class)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J9SRmDduBFEd"
      },
      "source": [
        "RunMHAD2_1s('/content/drive/MyDrive/SNOW/UTD-MHAD1_1s.npz')\n",
        "# RunWHARF('data/LOSO/WHARF.npz')\n",
        "# RunWisdom('data/LOSO/WISDM.npz')\n",
        "# Run('data/LOSO/MHEALTH.npz')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3mEAvUK3BFHB"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}