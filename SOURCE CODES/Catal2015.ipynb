{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Catal2015.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "PviQeVhJvD8N"
      },
      "source": [
        "!pip install scikit-learn\n",
        "!pip install numpy==1.16.1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GplmBbz76mOv"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ipgexQOFpLKA"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "print(tf.test.gpu_device_name())\n",
        "print(\"Num GPUs Available: \",len(tf.config.experimental.list_physical_devices('GPU')))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X8vaK_8FcJ_Q"
      },
      "source": [
        "## Libraries\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
        "from sklearn.metrics.classification import accuracy_score, recall_score, f1_score\n",
        "import scipy.stats as st\n",
        "import sys\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "np.random.seed(12227)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sazvh-j5cKOK"
      },
      "source": [
        "def A(sample):\n",
        "    feat = []\n",
        "    for col in range(0,sample.shape[1]):\n",
        "        average = np.average(sample[:,col])\n",
        "        feat.append(average)\n",
        "\n",
        "    return feat\n",
        "\n",
        "def SD(sample):\n",
        "    feat = []\n",
        "    for col in range(0, sample.shape[1]):\n",
        "        std = np.std(sample[:, col])\n",
        "        feat.append(std)\n",
        "\n",
        "    return feat\n",
        "\n",
        "def AAD(sample):\n",
        "    feat = []\n",
        "    for col in range(0, sample.shape[1]):\n",
        "        data = sample[:, col]\n",
        "        add = np.mean(np.absolute(data - np.mean(data)))\n",
        "        feat.append(add)\n",
        "\n",
        "    return feat\n",
        "\n",
        "def ARA(sample):\n",
        "    #Average Resultant Acceleration[1]:\n",
        "    # Average of the square roots of the sum of the values of each axis squared âˆš(xi^2 + yi^2+ zi^2) over the ED\n",
        "    feat = []\n",
        "    sum_square = 0\n",
        "    sample = np.power(sample, 2)\n",
        "    for col in range(0, sample.shape[1]):\n",
        "        sum_square = sum_square + sample[:, col]\n",
        "\n",
        "    sample = np.sqrt(sum_square)\n",
        "    average = np.average(sample)\n",
        "    feat.append(average)\n",
        "    return feat\n",
        "\n",
        "def TBP(sample):\n",
        "    from scipy import signal\n",
        "    feat = []\n",
        "    sum_of_time = 0\n",
        "    for col in range(0, sample.shape[1]):\n",
        "        data = sample[:, col]\n",
        "        peaks = signal.find_peaks_cwt(data, np.arange(1,4))\n",
        "\n",
        "        feat.append(peaks)\n",
        "\n",
        "    return feat"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3BQJlOMkcKQu"
      },
      "source": [
        "## Feature Extraction\n",
        "\n",
        "def feature_extraction(X):\n",
        "    # Extracts the features, as mentioned by Catal et al. 2015\n",
        "    # Average - A,\n",
        "    # Standard Deviation - SD,\n",
        "    # Average Absolute Difference - AAD,\n",
        "    # Average Resultant Acceleration - ARA(1),\n",
        "    # Time Between Peaks - TBP\n",
        "    X_tmp = []\n",
        "    for sample in X:\n",
        "        features = A(sample)\n",
        "        features = np.hstack((features, A(sample)))\n",
        "        features = np.hstack((features, SD(sample)))\n",
        "        features = np.hstack((features, AAD(sample)))\n",
        "        features = np.hstack((features, ARA(sample)))\n",
        "        X_tmp.append(features)\n",
        "\n",
        "    X = np.array(X_tmp)\n",
        "    return X"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rmP0jFuGcKT2"
      },
      "source": [
        "# Classical Machine Learning Algos\n",
        "def train_j48(X, y):\n",
        "    from sklearn import tree\n",
        "    clf = tree.DecisionTreeClassifier()\n",
        "   \n",
        "    return clf\n",
        "\n",
        "def train_mlp(X, y):\n",
        "    from sklearn.neural_network import MLPClassifier\n",
        "    a = int((X.shape[1] + np.amax(y)) / 2 )#Default param of weka, amax(y) gets the number of classes\n",
        "    clf = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes = (a,),\n",
        "                        learning_rate_init=0.3, momentum=0.2, max_iter=500, #Default param of weka\n",
        "                        )\n",
        "    \n",
        "    return clf\n",
        "\n",
        "def train_logistic_regression(X, y):\n",
        "    from sklearn.linear_model import LogisticRegression\n",
        "    clf = LogisticRegression(multi_class='ovr')\n",
        "    \n",
        "    return clf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gIgWeUPacKXR"
      },
      "source": [
        "def DataPreparation(data_input_file):\n",
        "  print('Catal et al. 2015 {}'.format(data_input_file))\n",
        "  data = np.load(data_input_file)\n",
        "  X = data['X']\n",
        "  X = X[:, 0, :, :]\n",
        "  Y = data['y']\n",
        "  folds = data['folds']\n",
        "  classes_number = Y.shape[1]\n",
        "  Y = np.argmax(Y, axis=1)\n",
        "  return X,Y,folds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qA_nv7Y8cKap"
      },
      "source": [
        "def Train(X,Y,folds):\n",
        "  avg_acc = []\n",
        "  avg_recall = []\n",
        "  avg_f1 = []\n",
        "  for i in range(0, len(folds)):\n",
        "    train_idx = folds[i][0]\n",
        "    test_idx = folds[i][1]\n",
        "\n",
        "    X_train = X[train_idx]\n",
        "    X_test = X[test_idx]\n",
        "\n",
        "    X_train = feature_extraction(X_train)\n",
        "    X_test = feature_extraction(X_test)\n",
        "\n",
        "    j_48 = train_j48(X_train,Y[train_idx])\n",
        "    mlp = train_mlp(X_train, Y[train_idx])\n",
        "    logistic_regression = train_logistic_regression(X_train, Y[train_idx])\n",
        "\n",
        "    majority_voting = VotingClassifier(estimators=[('dt', j_48), ('mlp', mlp), ('lr', logistic_regression)], voting='soft')\n",
        "    majority_voting.fit(X_train, Y[train_idx])\n",
        "    tmp = majority_voting.predict(X_test)\n",
        "\n",
        "    acc_fold = accuracy_score(Y[test_idx], tmp)\n",
        "    avg_acc.append(acc_fold)\n",
        "\n",
        "    recall_fold = recall_score(Y[test_idx], tmp, average='macro')\n",
        "    avg_recall.append(recall_fold)\n",
        "\n",
        "    f1_fold  = f1_score(Y[test_idx], tmp, average='macro')\n",
        "    avg_f1.append(f1_fold)\n",
        "\n",
        "    print('Accuracy[{:.4f}] Recall[{:.4f}] F1[{:.4f}] at fold[{}]'.format(acc_fold, recall_fold, f1_fold ,i+1))\n",
        "    print('________________________________________________________________')\n",
        "\n",
        "  return avg_acc, avg_recall,avg_f1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ak1ruapcKde"
      },
      "source": [
        "def ReportAccuracies(avg_acc, avg_recall,avg_f1):\n",
        "  ic_acc = st.t.interval(0.9, len(avg_acc) - 1, loc=np.mean(avg_acc), scale=st.sem(avg_acc))\n",
        "  ic_recall = st.t.interval(0.9, len(avg_recall) - 1, loc=np.mean(avg_recall), scale=st.sem(avg_recall))\n",
        "  ic_f1 = st.t.interval(0.9, len(avg_f1) - 1, loc=np.mean(avg_f1), scale=st.sem(avg_f1))\n",
        "  print('Mean Accuracy[{:.4f}] IC [{:.4f}, {:.4f}]'.format(np.mean(avg_acc), ic_acc[0], ic_acc[1]))\n",
        "  print('Mean Recall[{:.4f}] IC [{:.4f}, {:.4f}]'.format(np.mean(avg_recall), ic_recall[0], ic_recall[1]))\n",
        "  print('Mean F1[{:.4f}] IC [{:.4f}, {:.4f}]'.format(np.mean(avg_f1), ic_f1[0], ic_f1[1]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EGAZYYV-cKg-"
      },
      "source": [
        "def RunCatal(data_input_file):\n",
        "  X,Y,folds= DataPreparation(data_input_file)\n",
        "  avg_acc, avg_recall,avg_f1= Train(X,Y,folds)\n",
        "  ReportAccuracies(avg_acc, avg_recall,avg_f1 )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PHh3ZLSRcKjw"
      },
      "source": [
        "RunCatal('/content/drive/My Drive/SNOW/WISDM.npz')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ElRgF4WcKpB"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}