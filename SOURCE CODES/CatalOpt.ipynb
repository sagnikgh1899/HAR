{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CatalOpt.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "fclSdxyDCVR3"
      },
      "source": [
        "# !pip install scikit-learn\n",
        "# !pip install numpy==1.16.1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hR3Zh8nvCs-H"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "phmnM4R1CtAh"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
        "from sklearn.metrics.classification import accuracy_score, recall_score, f1_score\n",
        "import scipy.stats as st"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "knVPj8kmCtFq"
      },
      "source": [
        "def A(sample):\n",
        "    feat = []\n",
        "    for col in range(0,sample.shape[1]):\n",
        "        average = np.average(sample[:,col])\n",
        "        feat.append(average)\n",
        "\n",
        "    return feat\n",
        "\n",
        "def SD(sample):\n",
        "    feat = []\n",
        "    for col in range(0, sample.shape[1]):\n",
        "        std = np.std(sample[:, col])\n",
        "        feat.append(std)\n",
        "\n",
        "    return feat\n",
        "\n",
        "def AAD(sample):\n",
        "    feat = []\n",
        "    for col in range(0, sample.shape[1]):\n",
        "        data = sample[:, col]\n",
        "        add = np.mean(np.absolute(data - np.mean(data)))\n",
        "        feat.append(add)\n",
        "\n",
        "    return feat\n",
        "\n",
        "def ARA(sample):\n",
        "    #Average Resultant Acceleration[1]:\n",
        "    # Average of the square roots of the sum of the values of each axis squared âˆš(xi^2 + yi^2+ zi^2) over the ED\n",
        "    feat = []\n",
        "    sum_square = 0\n",
        "    sample = np.power(sample, 2)\n",
        "    for col in range(0, sample.shape[1]):\n",
        "        sum_square = sum_square + sample[:, col]\n",
        "\n",
        "    sample = np.sqrt(sum_square)\n",
        "    average = np.average(sample)\n",
        "    feat.append(average)\n",
        "    return feat\n",
        "\n",
        "def TBP(sample):\n",
        "    from scipy import signal\n",
        "    feat = []\n",
        "    sum_of_time = 0\n",
        "    for col in range(0, sample.shape[1]):\n",
        "        data = sample[:, col]\n",
        "        peaks = signal.find_peaks_cwt(data, np.arange(1,4))\n",
        "\n",
        "        feat.append(peaks)\n",
        "\n",
        "    return feat"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vCUGqPYhCtIC"
      },
      "source": [
        "## Feature Extraction\n",
        "\n",
        "def feature_extraction(X):\n",
        "    # Extracts the features, as mentioned by Catal et al. 2015\n",
        "    # Average - A,\n",
        "    # Standard Deviation - SD,\n",
        "    # Average Absolute Difference - AAD,\n",
        "    # Average Resultant Acceleration - ARA(1),\n",
        "    # Time Between Peaks - TBP\n",
        "    X_tmp = []\n",
        "    for sample in X:\n",
        "        features = A(sample)\n",
        "        features = np.hstack((features, A(sample)))\n",
        "        features = np.hstack((features, SD(sample)))\n",
        "        features = np.hstack((features, AAD(sample)))\n",
        "        features = np.hstack((features, ARA(sample)))\n",
        "        X_tmp.append(features)\n",
        "\n",
        "    X = np.array(X_tmp)\n",
        "    return X"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5YmFvwepCtKY"
      },
      "source": [
        "# Classical Machine Learning Algos\n",
        "def train_j48(X, y):\n",
        "    from sklearn import tree\n",
        "    clf = tree.DecisionTreeClassifier()\n",
        "   \n",
        "    return clf\n",
        "\n",
        "def train_mlp(X, y):\n",
        "    from sklearn.neural_network import MLPClassifier\n",
        "    a = int((X.shape[1] + np.amax(y)) / 2 )#Default param of weka, amax(y) gets the number of classes\n",
        "    clf = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes = (a,),\n",
        "                        learning_rate_init=0.3, momentum=0.2, max_iter=500, #Default param of weka\n",
        "                        )\n",
        "    \n",
        "    return clf\n",
        "\n",
        "def train_logistic_regression(X, y):\n",
        "    from sklearn.linear_model import LogisticRegression\n",
        "    clf = LogisticRegression(multi_class='ovr')\n",
        "    \n",
        "    return clf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aHs7wPSCCtPg"
      },
      "source": [
        "def OpportunityDataSetAnalysis():\n",
        "  X_train=np.load('/content/drive/MyDrive/Opportunity/Opportunity_train_X.npz')['arr_0']\n",
        "  X_test=np.load('/content/drive/MyDrive/Opportunity/Opportunity_test_X.npz')['arr_0']\n",
        "  Y_train=np.load('/content/drive/MyDrive/Opportunity/Opportunity_train_y.npz')['arr_0']\n",
        "  Y_test=np.load('/content/drive/MyDrive/Opportunity/Opportunity_test_Y.npz')['arr_0']\n",
        "  Y_train = np.argmax(Y_train, axis=1)\n",
        "  Y_test = np.argmax(Y_test, axis=1)\n",
        "  return X_train,Y_train,X_test,Y_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "--PFz6dWCtUV"
      },
      "source": [
        "def TrainAndTestOpportunity(X_train,Y_train,X_test,Y_test):\n",
        "    X_train = feature_extraction(X_train)\n",
        "    X_test = feature_extraction(X_test)\n",
        "\n",
        "    j_48 = train_j48(X_train,Y_train)\n",
        "    mlp = train_mlp(X_train, Y_train)\n",
        "    logistic_regression = train_logistic_regression(X_train, Y_train)\n",
        "\n",
        "    majority_voting = VotingClassifier(estimators=[('dt', j_48), ('mlp', mlp), ('lr', logistic_regression)], voting='soft')\n",
        "    majority_voting.fit(X_train, Y_train)\n",
        "    tmp = majority_voting.predict(X_test)\n",
        "\n",
        "    acc = accuracy_score(Y_test, tmp)\n",
        "\n",
        "    recall = recall_score(Y_test, tmp, average='macro')\n",
        "\n",
        "    f1 = f1_score(Y_test, tmp, average='macro')\n",
        "\n",
        "    print('Accuracy[{:.4f}] Recall[{:.4f}] F1[{:.4f}]'.format(acc, recall, f1))\n",
        "    print('________________________________________________________________')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wTaIXSPRCtM9"
      },
      "source": [
        "def ReportAccuracies(avg_acc, avg_recall,avg_f1):\n",
        "  ic_acc = st.t.interval(0.9, len(avg_acc) - 1, loc=np.mean(avg_acc), scale=st.sem(avg_acc))\n",
        "  ic_recall = st.t.interval(0.9, len(avg_recall) - 1, loc=np.mean(avg_recall), scale=st.sem(avg_recall))\n",
        "  ic_f1 = st.t.interval(0.9, len(avg_f1) - 1, loc=np.mean(avg_f1), scale=st.sem(avg_f1))\n",
        "  print('Mean Accuracy[{:.4f}] IC [{:.4f}, {:.4f}]'.format(np.mean(avg_acc), ic_acc[0], ic_acc[1]))\n",
        "  print('Mean Recall[{:.4f}] IC [{:.4f}, {:.4f}]'.format(np.mean(avg_recall), ic_recall[0], ic_recall[1]))\n",
        "  print('Mean F1[{:.4f}] IC [{:.4f}, {:.4f}]'.format(np.mean(avg_f1), ic_f1[0], ic_f1[1]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QAeA5sIECtDF"
      },
      "source": [
        "def RunOpportunity():\n",
        "  X_train,Y_train,X_test,Y_test=OpportunityDataSetAnalysis()\n",
        "  TrainAndTestOpportunity(X_train,Y_train,X_test,Y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lTfO_r0WCtRz"
      },
      "source": [
        "RunOpportunity()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n3xcqyJnCtWm"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}