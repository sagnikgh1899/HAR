{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BevilacquaOpt.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "XmcCcLmQRleu"
      },
      "source": [
        "## Libraries Prequisities\n",
        "!pip install scikit-learn\n",
        "!pip install numpy==1.16.1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4q4fkzZlRrAd"
      },
      "source": [
        "import numpy as np\n",
        "import random\n",
        "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
        "from sklearn.metrics.classification import accuracy_score, recall_score, f1_score\n",
        "import scipy.stats as st"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pv7Ny_yYRrDd"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "print(tf.test.gpu_device_name())\n",
        "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uU_hBoYIRrFh"
      },
      "source": [
        "from tensorflow.keras.callbacks import Callback"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P8gz34s0RrHq"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I14XfyYnRrJ9"
      },
      "source": [
        "n_ep = 200\n",
        "loss = 0.2\n",
        "bs = 1000\n",
        "np.random.seed(12227)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "931YZAGzRrMf"
      },
      "source": [
        "def DataPreparation(data_input_file,data_target_file,test_file,test_target_file):\n",
        "  print('Bevilacqua  et al. 2019 {}'.format(data_input_file))\n",
        "  \n",
        "  X=np.load(data_input_file)\n",
        "  \n",
        "  Y = np.load(data_target_file)\n",
        "  \n",
        "  X_test=np.load(test_file)\n",
        "  Y_test=np.load(test_target_file)\n",
        "  return X.f.arr_0,Y.f.arr_0, X_test.f.arr_0,Y_test.f.arr_0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pV1cxpg1RrPC"
      },
      "source": [
        "def ReportAccuracies(avg_acc, avg_recall,avg_f1):\n",
        "  ic_acc = st.t.interval(0.9, len(avg_acc) - 1, loc=np.mean(avg_acc), scale=st.sem(avg_acc))\n",
        "  ic_recall = st.t.interval(0.9, len(avg_recall) - 1, loc=np.mean(avg_recall), scale=st.sem(avg_recall))\n",
        "  ic_f1 = st.t.interval(0.9, len(avg_f1) - 1, loc=np.mean(avg_f1), scale=st.sem(avg_f1))\n",
        "  print('Mean Accuracy[{:.4f}] IC [{:.4f}, {:.4f}]'.format(np.mean(avg_acc), ic_acc[0], ic_acc[1]))\n",
        "  print('Mean Recall[{:.4f}] IC [{:.4f}, {:.4f}]'.format(np.mean(avg_recall), ic_recall[0], ic_recall[1]))\n",
        "  print('Mean F1[{:.4f}] IC [{:.4f}, {:.4f}]'.format(np.mean(avg_f1), ic_f1[0], ic_f1[1]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QIRuShKYRrRj"
      },
      "source": [
        "def RunBevilacqua(data_input_file,data_target_file,test_file,test_target_file):\n",
        "  X,Y,X_test,Y_test= DataPreparation(data_input_file,data_target_file,test_file,test_target_file)\n",
        "  avg_acc, avg_recall,avg_f1= Train(X,Y,X_test,Y_test)\n",
        "  ReportAccuracies(avg_acc, avg_recall,avg_f1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NVB7C31sRrUN"
      },
      "source": [
        "def build_model_1(row,col,num_classes):\n",
        "  layers = [\n",
        "        tf.keras.layers.Conv2D(filters=10,kernel_size=(3, 5), activation = tf.nn.relu),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.MaxPool2D(pool_size=(3,3),strides = 1),\n",
        "\n",
        "        tf.keras.layers.Conv2D(filters=2,kernel_size=(2, 4),activation = tf.nn.relu),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.MaxPool2D(pool_size=(2,2),strides = 1),\n",
        "\n",
        "        tf.keras.layers.Conv2D(filters=2,kernel_size=(2, 2),activation = tf.nn.relu),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.MaxPool2D(pool_size=(3,2),strides = 1),\n",
        "      \n",
        "        tf.keras.layers.Flatten(),\n",
        "        tf.keras.layers.Dense(500, activation = tf.nn.relu),\n",
        "        tf.keras.layers.Dropout(0.5),\n",
        "        tf.keras.layers.Dense(25, activation = tf.nn.relu),\n",
        "        tf.keras.layers.Dropout(0.5),\n",
        "       \n",
        "        tf.keras.layers.Dense(num_classes, activation = 'softmax')\n",
        "    ]\n",
        "    \n",
        "  model = tf.keras.Sequential(layers)\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0TerkJy4RrWl"
      },
      "source": [
        "from sklearn.model_selection import KFold, StratifiedKFold\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T2iMWOmURrZe"
      },
      "source": [
        "def Train(X,y,X_test,Y_test):\n",
        "  avg_acc = []\n",
        "  avg_recall = []\n",
        "  avg_f1 = []\n",
        "  n_class = y.shape[1]\n",
        "  _,img_rows, img_cols = X.shape\n",
        "  X=X.reshape(X.shape[0],img_rows,img_cols,1)\n",
        "  _,img_rows_, img_cols_ = X_test.shape\n",
        "  X_test=X_test.reshape(X_test.shape[0],img_rows_,img_cols_,1)\n",
        "  \n",
        "  kf = KFold(n_splits=5, random_state=1442, shuffle=True)\n",
        "  kf.get_n_splits(X)\n",
        "  n_fold=1\n",
        "  for train_ids_indx, valid_ids_indx in kf.split(X):\n",
        "    \n",
        "    X_train = X[train_ids_indx]\n",
        "    X_valid = X[valid_ids_indx]\n",
        "    y_train= y[train_ids_indx]\n",
        "    y_valid=y[valid_ids_indx]\n",
        "\n",
        "   \n",
        "    model=build_model_1(img_rows,img_cols,n_class)\n",
        "    \n",
        "    model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='Adam')\n",
        "    model.fit(X_train, y_train, batch_size=64, epochs=300 ,validation_data=(X_valid, y_valid))\n",
        "    y_pred = model.predict(X_test)\n",
        "    y_pred = np.argmax(y_pred, axis=1)\n",
        "    y_true = np.argmax(Y_test, axis=1)\n",
        "    acc_fold = accuracy_score(y_true, y_pred)\n",
        "    avg_acc.append(acc_fold)\n",
        "    recall_fold = recall_score(y_true, y_pred, average='macro')\n",
        "    avg_recall.append(recall_fold)\n",
        "    f1_fold = f1_score(y_true, y_pred, average='macro')\n",
        "    avg_f1.append(f1_fold)\n",
        "    print('Accuracy[{:.4f}] Recall[{:.4f}] F1[{:.4f}] at fold[{}]'.format(acc_fold, recall_fold, f1_fold ,n_fold))\n",
        "    print('________________________________________________________________')\n",
        "    n_fold+=1\n",
        "    \n",
        "  return avg_acc, avg_recall,avg_f1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U6c6D0cQRrc6"
      },
      "source": [
        "tf.keras.backend.set_image_data_format('channels_last')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P3qrKRjLSJiL"
      },
      "source": [
        "RunBevilacqua('/content/drive/My Drive/Opportunity/Opportunity_train_X.npz','/content/drive/My Drive/Opportunity/Opportunity_train_y.npz','/content/drive/My Drive/Opportunity/Opportunity_test_X.npz','/content/drive/My Drive/Opportunity/Opportunity_test_Y.npz')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZSQpfswrTAWX"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}